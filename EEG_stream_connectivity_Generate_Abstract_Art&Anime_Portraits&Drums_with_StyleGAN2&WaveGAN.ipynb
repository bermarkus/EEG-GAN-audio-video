{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEG_stream_connectivity_Generate_Abstract_Art&Anime_Portraits&Drums_with_StyleGAN2&WaveGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neuroidss/EEG-GAN-audio-video/blob/main/EEG_stream_connectivity_Generate_Abstract_Art%26Anime_Portraits%26Drums_with_StyleGAN2%26WaveGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD0U8i5zIaZJ"
      },
      "source": [
        "generate_tf1=True\n",
        "#generate_tf1=False\n",
        "#generate_tf2=True\n",
        "generate_tf2=False\n",
        "\n",
        "#generate_tpu=True\n",
        "generate_tpu=False\n",
        "generate_gpu=True\n",
        "#generate_gpu=False\n",
        "\n",
        "generate_stylegan2=True\n",
        "#generate_stylegan2=False\n",
        "\n",
        "#generate_stylegan2_rosasalberto_tf_2_x=True\n",
        "generate_stylegan2_rosasalberto_tf_2_x=False\n",
        "#generate_anime_tf2_npy=True\n",
        "generate_anime_tf2_npy=False\n",
        "#generate_this_anime_does_not_exist_tf2_npy=True\n",
        "generate_this_anime_does_not_exist_tf2_npy=False\n",
        "#generate_anime_protraits_tf2_npy=True\n",
        "generate_anime_protraits_tf2_npy=False\n",
        "#generate_abctract_art_tf2_npy=True\n",
        "generate_abctract_art_tf2_npy=False\n",
        "#generate_tf2_npy=True\n",
        "generate_tf2_npy=False\n",
        "\n",
        "#generate_stylegan2_moono_tf_2_x=True\n",
        "generate_stylegan2_moono_tf_2_x=False\n",
        "#generate_anime_tf2=True\n",
        "generate_anime_tf2=False\n",
        "\n",
        "#generate_stylegan2_shawwn_tpu=True\n",
        "generate_stylegan2_shawwn_tpu=False\n",
        "#generate_stylegan2_cyrilzakka_tpu=True\n",
        "generate_stylegan2_cyrilzakka_tpu=False\n",
        "#generate_stylegan2_nvlabs=True\n",
        "generate_stylegan2_nvlabs=False\n",
        "#generate_anime=True\n",
        "generate_anime=False\n",
        "\n",
        "#generate_stylegan2_shawwn=True\n",
        "generate_stylegan2_shawwn=False\n",
        "#generate_this_anime_does_not_exist=True\n",
        "generate_this_anime_does_not_exist=False\n",
        "\n",
        "generate_stylegan2_ada=True\n",
        "#generate_stylegan2_ada=False\n",
        "#generate_anime_protraits=True\n",
        "generate_anime_protraits=False\n",
        "generate_abctract_art=True\n",
        "#generate_abctract_art=False\n",
        "\n",
        "#generate_wavegan=True\n",
        "generate_wavegan=False\n",
        "\n",
        "#generate_drums=True\n",
        "generate_drums=False\n",
        "\n",
        "##biosemi16-2:\n",
        "#ch_names = ['FP1','F3','T7','C3','P3','Pz','O1','O2','P4','C4','T8','F4','FP2','Fz']\n",
        "#ch_locations=[0,3,6,7,11,12,14,16,18,22,23,26,29,30]\n",
        "\n",
        "#biosemi32\n",
        "ch_names = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','FP2','Fz','Cz']\n",
        "ch_locations=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]\n",
        "##Bernard's 19ch:\n",
        "#ch_names = [\"FP2\",\"FP1\",\"O2\",\"T6\",\"T4\",\"F8\",\"F4\",\"C4\",\"P4\",\"F3\",\"C3\",\"P3\",\"O1\",\"T5\",\"T3\",\"F7\",\"FZ\",\"PZ\"]#,\"other\"]\n",
        "#ch_locations=[4,24,0,1,2,3,5,6,7,25,26,27,28,29,30,31,16,12]#,8]\n",
        "##Bernard's 2ch:\n",
        "#ch_names = [\"FP2\",\"FP1\"]#,\"other\"]\n",
        "#ch_locations=[4,24]#,8]\n",
        "\n",
        "bands = [[8.,12.]]\n",
        "#bands = [[4.,7.],[8.,12.],[13.,29.]]\n",
        "#bands = [[8.,12.],[8.,12.],[8.,12.]]\n",
        "methods = ['coh']\n",
        "#methods = ['ciplv']\n",
        "#methods = ['coh', 'plv', 'ciplv', 'ppc', 'pli', 'wpli']\n",
        "\n",
        "duration=5*1/8\n",
        "overlap=duration-0.1\n",
        "xsize=400\n",
        "ysize=400\n",
        "hz=44100\n",
        "#fps=hz/(32768)\n",
        "\n",
        "if generate_wavegan:\n",
        "  fps=hz/(32768*2)\n",
        "if generate_stylegan2:\n",
        "  fps=2\n",
        "\n",
        "if 1/fps-0.2>duration:\n",
        "  duration=1/fps-0.2\n",
        "  overlap=duration-0.1\n",
        "\n",
        "if generate_wavegan:\n",
        "  dim = 100\n",
        "if generate_stylegan2:\n",
        "  dim = 512\n",
        "if generate_stylegan2_shawwn:\n",
        "  dim = 1024\n",
        "\n",
        "stepSize = 1/pow(2,24)\n",
        "vref = 2.50 #2.5V voltage ref +/- 250nV\n",
        "gain = 8\n",
        "\n",
        "vscale = (vref/gain)*stepSize #volts per step.\n",
        "uVperStep = 1000000 * ((vref/gain)*stepSize) #uV per step.\n",
        "scalar = 1/(1000000 / ((vref/gain)*stepSize)) #steps per uV."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WErNtyaMBkg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ff6b14-42a0-448c-be47-dbc3aed81b5d"
      },
      "source": [
        "if generate_tf1:\n",
        "  %tensorflow_version 1.x\n",
        "if generate_tf2:\n",
        "  %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Tensorflow version: 1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLsvM-V7Oh9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c140e830-b971-496d-bfb5-820d8229f380"
      },
      "source": [
        "if generate_tf1:\n",
        " if generate_gpu:\n",
        "  from tensorflow.python.client import device_lib\n",
        "  print(device_lib.list_local_devices())\n",
        "\n",
        " if generate_tpu:\n",
        "  import os\n",
        "  import tensorflow.compat.v1 as tf\n",
        "  tf.disable_eager_execution()\n",
        "  import pprint\n",
        "  assert 'COLAB_TPU_ADDR' in os.environ, 'Did you forget to switch to TPU?'\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(tpu_address) as sess:\n",
        "    devices = sess.list_devices()\n",
        "  pprint.pprint(devices)\n",
        "  device_is_tpu = [True if 'TPU' in str(x) else False for x in devices]\n",
        "  assert True in device_is_tpu, 'Did you forget to switch to TPU?'\n",
        "\n",
        "if generate_tf2:\n",
        " try: # detect TPUs\n",
        "  tpu = None\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.TPUStrategy(tpu)\n",
        " except ValueError: # detect GPUs\n",
        "  strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
        "  #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
        "\n",
        " print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 17647674931864351228\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 16898295714649943611\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 11447850219564599548\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11338832282\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 12777311078653637763\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaHracqcMbGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d7efc3-d6f2-4623-a7b6-40900a82b8be"
      },
      "source": [
        "if generate_stylegan2_nvlabs:\n",
        "  %cd /content\n",
        "  !git clone https://github.com/NVlabs/stylegan2.git\n",
        "  %cd /content/stylegan2\n",
        "if generate_stylegan2_ada:\n",
        "  %cd /content\n",
        "  !git clone https://github.com/NVlabs/stylegan2-ada.git\n",
        "  %cd /content/stylegan2-ada\n",
        "if generate_stylegan2_shawwn:\n",
        "  %cd /content\n",
        "  !git clone https://github.com/shawwn/stylegan2.git stylegan2-shawwn\n",
        "  %cd /content/stylegan2-shawwn\n",
        "if generate_stylegan2_cyrilzakka_tpu:\n",
        "  %cd /content\n",
        "  !git clone https://github.com/cyrilzakka/stylegan2-tpu.git stylegan2-cyrilzakka-tpu\n",
        "  %cd /content/stylegan2-cyrilzakka-tpu\n",
        "  #!pip install -r requirements.txt\n",
        "  #!pip install tensorflow-gpu==2.4.0\n",
        "  #!pip install Keras-Applications==1.0.7\n",
        "  #!pip install Keras-Preprocessing==1.0.9\n",
        "if generate_stylegan2_shawwn_tpu:\n",
        "  %cd /content\n",
        "  !git clone --branch tpu https://github.com/shawwn/stylegan2.git stylegan2-shawwn-tpu\n",
        "  %cd /content/stylegan2-shawwn-tpu\n",
        "if generate_stylegan2_moono_tf_2_x:\n",
        "  %cd /content\n",
        "  #!git clone https://github.com/NVlabs/stylegan2.git\n",
        "  #%cd /content/stylegan2\n",
        "  !git clone https://github.com/moono/stylegan2-tf-2.x.git\n",
        "  %cd /content/stylegan2-tf-2.x\n",
        "if generate_stylegan2_rosasalberto_tf_2_x:\n",
        "  %cd /content\n",
        "  !git clone https://github.com/rosasalberto/StyleGAN2-TensorFlow-2.x.git\n",
        "  %cd /content/StyleGAN2-TensorFlow-2.x\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'stylegan2-ada' already exists and is not an empty directory.\n",
            "/content/stylegan2-ada\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqYszSxLKjt1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdd1450-7c9e-4b8e-8f4e-6ae1a60e2eb3"
      },
      "source": [
        "!pip install googledrivedownloader\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "if generate_drums:\n",
        "  files_path = [['1ZJir-_ls92s56LFmw_HVuQ7ANqFFN5WG', '/content/model/model.ckpt-18637.data-00000-of-00001'],\n",
        "              ['1d5ayi4w-70AvKYPk-8sXzsSzpK1jMRgm', '/content/model/model.ckpt-18637.index'],  \n",
        "              ['15CWn0yK3FKsHbAOGNLQYVg4eZC1oNIrL', '/content/model/model.ckpt-18637.meta'],  \n",
        "              ['1x5QEFeoochk-rhvtvJc98kIB5_SAwn0u', '/content/model/args.txt'],  \n",
        "              ['1UgSZaBTCTDXaPbfv8l0wmpHbD5u051o5', '/content/model/graph.pbtxt'],  \n",
        "              ['1LGfAkuOFvA3NdFE_rOq9WyeXGGgEOf0F', '/content/model/checkpoint'],  \n",
        "              ['1bPD0bXCC_18oWbUjmjkacF-CShlA6yNd', '/content/model/infer/infer.pbtxt'],  \n",
        "              ['13OQuRx7Ku6KJ9o9FU-JN3yB0Njul9Vem', '/content/model/infer/infer.meta']]\n",
        "if generate_abctract_art:\n",
        "  files_path = [['1ie1vWw1JNsfrZWRtMvhteqzVz4mt4KGa', '/content/model/sg2-ada_abstract_network-snapshot-000188.pkl',\n",
        "                 'sg2-ada_abstract_network-snapshot-000188','stylegan2-ada']]\n",
        "if generate_anime_protraits:\n",
        "  files_path = [['1aUrChOhq5jDEddZK1v_Dp1vYNlHSBL9o', '/content/model/sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664.pkl', \n",
        "                 'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664','stylegan2-ada']]\n",
        "if generate_this_anime_does_not_exist:\n",
        "  files_path = [['1sdnL-lIl2kYAnuleafK-5GPiLNHfxh4W', '/content/model/sg2-ext_aydao-anime-danbooru2019s-512-5268480.pkl', \n",
        "                 'sg2-ext_aydao-anime-danbooru2019s-512-5268480','stylegan2-shawwn']]\n",
        "  #files_path = [['1l5zG0g_RMEAwFUK_veD1EZweVEoY9gUT', '/content/model/aydao-anime-danbooru2019s-512-5268480.pkl']]\n",
        "#  files_path = [['1BHeqOZ58WZ-vACR2MJkh1ZVbJK2B-Kle', '/content/model/network-snapshot-017325.pkl']]\n",
        "#  files_path = [['1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez', '/content/model/network-snapshot-018528.pkl']]\n",
        "if generate_anime:\n",
        "  files_path = [['1YckI8gwqPbZBI8X4eaQAJCgWx-CqCTdi', '/content/model/sg2_anime_network-snapshot-018528.pkl', \n",
        "                 'sg2_anime_network-snapshot-018528']]\n",
        "if generate_anime_tf2:\n",
        "  files_path = [['1-1neAg_FUymzBvCStMe7CfV94-VD22kk', '/content/stylegan2-tf-2.x/official-converted/cuda/ckpt-0.data-00000-of-00001'],\n",
        "              ['1-4ih0wi68y4xH5tg0_kClpuWDSnvdmoE', '/content/stylegan2-tf-2.x/official-converted/cuda/ckpt-0.index'],\n",
        "              ['1-C6H58vmfZykqWpilR1u9puH8oPFQtcQ', '/content/stylegan2-tf-2.x/official-converted/cuda/checkpoint']]\n",
        "if generate_abctract_art_tf2_npy:\n",
        "  files_path = [['1cauGWIVGGiMJA0_OZftJU3-rVAVdFwZM', '/content/StyleGAN2-TensorFlow-2.x/weights/sg2-ada_abstract_network-snapshot-000188.npy',\n",
        "                 'sg2-ada_abstract_network-snapshot-000188']]\n",
        "if generate_anime_protraits_tf2_npy:\n",
        "  files_path = [['1-Cp-RRJnjvfCIrD0ylaUYxvLbxN4aj8K', '/content/StyleGAN2-TensorFlow-2.x/weights/sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664.npy', \n",
        "                 'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664']]\n",
        "if generate_this_anime_does_not_exist_tf2_npy:\n",
        "  files_path = [['1-36-rfueVBWvigBvCuwzrXKl1AeVtzu6', '/content/StyleGAN2-TensorFlow-2.x/weights/sg2-ext_aydao-anime-danbooru2019s-512-5268480.npy', \n",
        "                 'sg2-ext_aydao-anime-danbooru2019s-512-5268480']]\n",
        "if generate_anime_tf2_npy:\n",
        "  files_path = [['1--ajK29hgTTAYNcZhQk9lLFhwUlXqxNA', '/content/StyleGAN2-TensorFlow-2.x/weights/sg2_anime_network-snapshot-018528.npy', \n",
        "                 'sg2_anime_network-snapshot-018528']]\n",
        "\n",
        "for i in range(len(files_path)):\n",
        "  gdd.download_file_from_google_drive(file_id=files_path[i][0], dest_path=files_path[i][1])\n",
        "\n",
        "if generate_stylegan2:\n",
        "  import PIL.Image \n",
        "  !pip install tqdm\n",
        "  from tqdm import tqdm\n",
        "  !pip install imageio==2.4.1\n",
        "  !pip install imageio-ffmpeg==0.4.3 pyspng==0.1.0\n",
        "\n",
        "if generate_stylegan2_rosasalberto_tf_2_x:\n",
        "  import tensorflow as tf\n",
        "  import numpy as np\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  from utils.utils_stylegan2 import convert_images_to_uint8\n",
        "\n",
        "  def generate_and_plot_images(gen, seed, w_avg, truncation_psi=1):\n",
        "    \"\"\" plot images from generator output \"\"\"\n",
        "    \n",
        "    fig, ax = plt.subplots(1,3,figsize=(15,15))\n",
        "    for i in range(3):\n",
        "    \n",
        "        # creating random latent vector\n",
        "        rnd = np.random.RandomState(seed)\n",
        "        z = rnd.randn(1, 512).astype('float32')\n",
        "\n",
        "        # running mapping network\n",
        "        dlatents = gen.mapping_network(z)\n",
        "        # adjusting dlatents depending on truncation psi, if truncatio_psi = 1, no adjust\n",
        "        dlatents = w_avg + (dlatents - w_avg) * truncation_psi \n",
        "        # running synthesis network\n",
        "        out = gen.synthesis_network(dlatents)\n",
        "\n",
        "        #converting image/s to uint8\n",
        "        img = convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n",
        "\n",
        "        #plotting images\n",
        "        ax[i].axis('off')\n",
        "        img_plot = ax[i].imshow(img.numpy()[0])\n",
        "        \n",
        "        seed += 1\n",
        "\n",
        "  impl = 'ref' # 'ref' if cuda is not available in your machine\n",
        "  gpu = False # False if tensorflow cpu is used\n",
        "  if generate_tpu:\n",
        "    impl = 'ref' # 'ref' if cuda is not available in your machine\n",
        "    gpu = False # False if tensorflow cpu is used\n",
        "  if generate_gpu:\n",
        "    impl = 'cuda' # 'ref' if cuda is not available in your machine\n",
        "    gpu = True # False if tensorflow cpu is used\n",
        "\n",
        "  import tensorflow as tf\n",
        "  import numpy as np\n",
        "\n",
        "  from utils.weights_map import available_weights, synthesis_weights, mapping_weights, weights_stylegan2_dir\n",
        "  from utils.utils_stylegan2 import nf\n",
        "  from layers.dense_layer import DenseLayer\n",
        "  from layers.synthesis_main_layer import SynthesisMainLayer\n",
        "  from layers.to_rgb_layer import ToRgbLayer\n",
        "  from dnnlib.ops.upfirdn_2d import upsample_2d\n",
        "\n",
        "  class MappingNetwork(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    StyleGan2 generator mapping network, from z to dlatents for tensorflow 2.x\n",
        "    \"\"\"\n",
        "    def __init__(self, resolution=1024, **kwargs):\n",
        "        \n",
        "        super(MappingNetwork, self).__init__(**kwargs)\n",
        "        \n",
        "        self.dlatent_size = 512\n",
        "        self.dlatent_vector = (int(np.log2(resolution))-1)*2\n",
        "        self.mapping_layers = 8\n",
        "        self.lrmul = 0.01\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.weights_dict = {}\n",
        "        for i in range(self.mapping_layers):\n",
        "            setattr(self, 'Dense{}'.format(i), DenseLayer(fmaps=512, lrmul=self.lrmul, name='Dense{}'.format(i)))\n",
        "    \n",
        "        self.g_mapping_broadcast = tf.keras.layers.RepeatVector(self.dlatent_vector)\n",
        "            \n",
        "    def call(self, z):\n",
        "        \n",
        "        z = tf.cast(z, 'float32')\n",
        "        \n",
        "        # Normalize inputs\n",
        "        scale = tf.math.rsqrt(tf.reduce_mean(tf.square(z), axis=1, keepdims=True) + 1e-8)\n",
        "        x = tf.math.multiply(z, scale)\n",
        "        \n",
        "        # Mapping\n",
        "        for i in range(self.mapping_layers):\n",
        "        \n",
        "            x = getattr(self, 'Dense{}'.format(i))(x)\n",
        "            x = tf.math.multiply(tf.nn.leaky_relu(x, 0.2), tf.math.sqrt(2.))\n",
        "        \n",
        "        # Broadcasting\n",
        "        dlatents = self.g_mapping_broadcast(x)\n",
        "        \n",
        "        return dlatents\n",
        "\n",
        "  class SynthesisNetwork(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    StyleGan2 generator synthesis network from dlatents to img tensor for tensorflow 2.x\n",
        "    \"\"\"\n",
        "    def __init__(self, resolution=1024, impl='cuda', gpu=True, **kwargs):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        resolution : int, optional\n",
        "            Resolution output of the synthesis network, will be parsed to the floor integer power of 2. \n",
        "            The default is 1024.\n",
        "        impl : str, optional\n",
        "            Wether to run some convolutions in custom tensorflow operations or cuda operations. 'ref' and 'cuda' available.\n",
        "            The default is 'cuda'.\n",
        "        gpu : boolean, optional\n",
        "            Wether to use gpu. The default is True.\n",
        "        \"\"\"\n",
        "        super(SynthesisNetwork, self).__init__(**kwargs)\n",
        "        \n",
        "        self.impl = impl\n",
        "        self.gpu = gpu\n",
        "        self.resolution = resolution\n",
        "        \n",
        "        self.resolution_log2 = int(np.log2(self.resolution))\n",
        "        self.resample_kernel = [1, 3, 3, 1]\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        \n",
        "        #constant layer\n",
        "        self.const_4_4 = self.add_weight(name='4x4/Const/const', shape=(1, 512, 4, 4), \n",
        "                                        initializer=tf.random_normal_initializer(0, 1), trainable=True)\n",
        "        #early layer 4x4\n",
        "        self.layer_4_4 = SynthesisMainLayer(fmaps=nf(1), impl=self.impl, gpu=self.gpu, name='4x4')\n",
        "        self.torgb_4_4 = ToRgbLayer(impl=self.impl, gpu=self.gpu, name='4x4')\n",
        "        #main layers\n",
        "        for res in range(3, self.resolution_log2 + 1):\n",
        "            res_str = str(2**res)\n",
        "            setattr(self, 'layer_{}_{}_up'.format(res_str, res_str), \n",
        "                    SynthesisMainLayer(fmaps=nf(res-1), impl=self.impl, gpu=self.gpu, up=True, name='{}x{}'.format(res_str, res_str)))\n",
        "            setattr(self, 'layer_{}_{}'.format(res_str, res_str), \n",
        "                    SynthesisMainLayer(fmaps=nf(res-1), impl=self.impl, gpu=self.gpu, name='{}x{}'.format(res_str, res_str)))\n",
        "            setattr(self, 'torgb_{}_{}'.format(res_str, res_str), \n",
        "                    ToRgbLayer(impl=self.impl, gpu=self.gpu, name='{}x{}'.format(res_str, res_str)))\n",
        "        \n",
        "    def call(self, dlatents_in):\n",
        "        \n",
        "        dlatents_in = tf.cast(dlatents_in, 'float32')\n",
        "        y = None\n",
        "        \n",
        "        # Early layers\n",
        "        x = tf.tile(tf.cast(self.const_4_4, 'float32'), [tf.shape(dlatents_in)[0], 1, 1, 1])\n",
        "        x = self.layer_4_4(x, dlatents_in[:, 0])\n",
        "        y = self.torgb_4_4(x, dlatents_in[:, 1], y)\n",
        "                \n",
        "        # Main layers\n",
        "        for res in range(3, self.resolution_log2 + 1):\n",
        "            x = getattr(self, 'layer_{}_{}_up'.format(2**res, 2**res))(x, dlatents_in[:, res*2-5])\n",
        "            x = getattr(self, 'layer_{}_{}'.format(2**res, 2**res))(x, dlatents_in[:, res*2-4])\n",
        "            y = upsample_2d(y, k=self.resample_kernel, impl=self.impl, gpu=self.gpu)\n",
        "            y = getattr(self, 'torgb_{}_{}'.format(2**res, 2**res))(x, dlatents_in[:, res*2-3], y)\n",
        "                    \n",
        "        images_out = y\n",
        "        return tf.identity(images_out, name='images_out')\n",
        "    \n",
        "  class StyleGan2Generator(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    StyleGan2 generator config f for tensorflow 2.x\n",
        "    \"\"\"\n",
        "    def __init__(self, resolution=1024, weights=None, impl='cuda', gpu=True, **kwargs):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        resolution : int, optional\n",
        "            Resolution output of the synthesis network, will be parsed \n",
        "            to the floor integer power of 2. \n",
        "            The default is 1024.\n",
        "        weights : string, optional\n",
        "            weights name in weights dir to be loaded. The default is None.\n",
        "        impl : str, optional\n",
        "            Wether to run some convolutions in custom tensorflow operations \n",
        "            or cuda operations. 'ref' and 'cuda' available.\n",
        "            The default is 'cuda'.\n",
        "        gpu : boolean, optional\n",
        "            Wether to use gpu. The default is True.\n",
        "        \"\"\"\n",
        "        super(StyleGan2Generator, self).__init__(**kwargs)\n",
        "        \n",
        "        self.resolution = resolution\n",
        "        if weights is not None: self.__adjust_resolution(weights)\n",
        "\n",
        "        self.mapping_network = MappingNetwork(resolution=self.resolution,name='Mapping_network')\n",
        "        self.synthesis_network = SynthesisNetwork(resolution=self.resolution, impl=impl, \n",
        "                                                  gpu=gpu, name='Synthesis_network')\n",
        "        \n",
        "        # load weights\n",
        "        if weights is not None:\n",
        "            #we run the network to define it, not the most efficient thing to do...\n",
        "            _ = self(tf.zeros(shape=(1, 512)))\n",
        "            self.__load_weights(weights)\n",
        "        \n",
        "    def call(self, z):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        z : tensor, latent vector of shape [batch, 512]\n",
        "        Returns\n",
        "        -------\n",
        "        img : tensor, image generated by the generator of shape  [batch, channel, height, width]\n",
        "        \"\"\"\n",
        "        dlatents = self.mapping_network(z)\n",
        "        img = self.synthesis_network(dlatents)\n",
        "\n",
        "        return img\n",
        "    \n",
        "    def __adjust_resolution(self, weights_name):\n",
        "        \"\"\"\n",
        "        Adjust resolution of the synthesis network output. \n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        weights_name : name of the weights\n",
        "        Returns\n",
        "        -------\n",
        "        None.\n",
        "        \"\"\"\n",
        "        if  weights_name == 'ffhq': \n",
        "            self.resolution = 1024\n",
        "        elif weights_name == 'car': \n",
        "            self.resolution = 512\n",
        "        elif weights_name in ['cat', 'church', 'horse']: \n",
        "            self.resolution = 256\n",
        "        elif weights_name == 'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664': \n",
        "            self.resolution = 512\n",
        "        elif weights_name == 'sg2_anime_network-snapshot-018528': \n",
        "            self.resolution = 512\n",
        "        elif weights_name == 'sg2-ext_aydao-anime-danbooru2019s-512-5268480': \n",
        "            self.resolution = 1024\n",
        "        elif weights_name == 'sg2-ada_abstract_network-snapshot-000188': \n",
        "            self.resolution = 512    \n",
        "    def __load_weights(self, weights_name):\n",
        "        \"\"\"\n",
        "        Load pretrained weights, stored as a dict with numpy arrays.\n",
        "        Parameters\n",
        "        ----------\n",
        "        weights_name : name of the weights\n",
        "        Returns\n",
        "        -------\n",
        "        None.\n",
        "        \"\"\"\n",
        "        \n",
        "        if (weights_name in available_weights) and type(weights_name) == str:\n",
        "            data = np.load(weights_stylegan2_dir + weights_name + '.npy', allow_pickle=True)[()]\n",
        "            #datatmp = np.load(weights_stylegan2_dir + weights_name + '.npy', allow_pickle=True)[()]\n",
        "            #data=datatmp.copy()\n",
        "            #for key in datatmp.keys(): \n",
        "            #  if not (key[:4]=='disc'):\n",
        "            #    del data[key]\n",
        "            \n",
        "            weights_mapping = [data.get(key) for key in mapping_weights]\n",
        "            #print(weights_mapping)\n",
        "            weights_synthesis = [data.get(key) for key in synthesis_weights[weights_name]]\n",
        "            #print(weights_synthesis)\n",
        "            \n",
        "            self.mapping_network.set_weights(weights_mapping)\n",
        "            self.synthesis_network.set_weights(weights_synthesis)\n",
        "            \n",
        "            print(\"Loaded {} generator weights!\".format(weights_name))\n",
        "        else:\n",
        "            raise Exception('Cannot load {} weights'.format(weights_name))\n",
        "\n",
        "  def generate_and_plot_images_notrunc(gen, seed):\n",
        "    \"\"\" plot images from generator output \"\"\"\n",
        "    \n",
        "    fig, ax = plt.subplots(1,3,figsize=(15,15))\n",
        "    for i in range(3):\n",
        "    \n",
        "        # creating random latent vector\n",
        "        rnd = np.random.RandomState(seed)\n",
        "        z = rnd.randn(1, 512).astype('float32')\n",
        "\n",
        "        # running mapping network\n",
        "        dlatents = gen.mapping_network(z)\n",
        "        # adjusting dlatents depending on truncation psi, if truncatio_psi = 1, no adjust\n",
        "        #dlatents = w_avg + (dlatents - w_avg) * truncation_psi \n",
        "        # running synthesis network\n",
        "        out = gen.synthesis_network(dlatents)\n",
        "\n",
        "        #converting image/s to uint8\n",
        "        img = convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n",
        "\n",
        "        #plotting images\n",
        "        ax[i].axis('off')\n",
        "        img_plot = ax[i].imshow(img.numpy()[0])\n",
        "        #plt.axis('off')\n",
        "        #plt.imshow(img.numpy()[0])\n",
        "        #plt.show()\n",
        "        seed += 1\n",
        "\n",
        "\n",
        "  weights_name = files_path[0][2]\n",
        "\n",
        "  from utils.weights_map import synthesis_weights_1024, synthesis_weights_512, synthesis_weights_256\n",
        "  from utils.weights_map import discriminator_weights_1024, discriminator_weights_512, discriminator_weights_256\n",
        "\n",
        "  available_weights = ['ffhq', 'car', 'cat', 'church', 'horse', \n",
        "    'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664',\n",
        "    'sg2_anime_network-snapshot-018528',\n",
        "    'sg2-ext_aydao-anime-danbooru2019s-512-5268480',\n",
        "    'sg2-ada_abstract_network-snapshot-000188']\n",
        "\n",
        "  synthesis_weights = {\n",
        "    'ffhq' : synthesis_weights_1024,\n",
        "    'car' : synthesis_weights_512,\n",
        "    'cat' : synthesis_weights_256,\n",
        "    'horse' : synthesis_weights_256,\n",
        "    'church' : synthesis_weights_256,\n",
        "    'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664' : synthesis_weights_512,\n",
        "    'sg2_anime_network-snapshot-018528' : synthesis_weights_512,\n",
        "    'sg2-ext_aydao-anime-danbooru2019s-512-5268480' : synthesis_weights_1024,\n",
        "    'sg2-ada_abstract_network-snapshot-000188' : synthesis_weights_512\n",
        "    }\n",
        "\n",
        "  discriminator_weights = {\n",
        "    'ffhq' : discriminator_weights_1024,\n",
        "    'car' : discriminator_weights_512,\n",
        "    'cat' : discriminator_weights_256,\n",
        "    'horse' : discriminator_weights_256,\n",
        "    'church' : discriminator_weights_256,\n",
        "    'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664' : discriminator_weights_512,\n",
        "    'sg2_anime_network-snapshot-018528' : discriminator_weights_512,\n",
        "    'sg2-ext_aydao-anime-danbooru2019s-512-5268480' : discriminator_weights_1024,\n",
        "    'sg2-ada_abstract_network-snapshot-000188' : discriminator_weights_512\n",
        "    }\n",
        "\n",
        "  # instantiating generator network\n",
        "  generator = StyleGan2Generator(weights=weights_name, impl=impl, gpu=gpu)\n",
        "\n",
        "  # loading w average\n",
        "  #w_average = np.load('weights/{}_dlatent_avg.npy'.format(weights_name))\n",
        "\n",
        "if generate_stylegan2_moono_tf_2_x:\n",
        "  \n",
        "  import os\n",
        "  import numpy as np\n",
        "  import tensorflow as tf\n",
        "  from PIL import Image\n",
        "  from stylegan2.utils import postprocess_images\n",
        "  from load_models import load_generator\n",
        "  from copy_official_weights import convert_official_weights_together\n",
        "  \n",
        "  if True:\n",
        "    from tf_utils import allow_memory_growth\n",
        "\n",
        "    allow_memory_growth()\n",
        "\n",
        "    # common variables\n",
        "    ckpt_dir_base = './official-converted'\n",
        "\n",
        "    use_custom_cuda=True\n",
        "    # saving phase\n",
        "    #for use_custom_cuda in [True, False]:\n",
        "    #    ckpt_dir = os.path.join(ckpt_dir_base, 'cuda') if use_custom_cuda else os.path.join(ckpt_dir_base, 'ref')\n",
        "    #    convert_official_weights_together(ckpt_dir, use_custom_cuda)\n",
        "\n",
        "    # inference phase\n",
        "    ckpt_dir_cuda = os.path.join(ckpt_dir_base, 'cuda')\n",
        "    ckpt_dir_ref = os.path.join(ckpt_dir_base, 'ref')\n",
        "\n",
        "    g_clone = load_generator(g_params=None, is_g_clone=True, ckpt_dir=ckpt_dir_cuda, custom_cuda=use_custom_cuda)\n",
        "\n",
        "#if generate_stylegan2_tpu:\n",
        "#  tflib.init_tf()\n",
        "#  import pretrained_networks\n",
        "#  _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "if generate_stylegan2 and generate_tf1:\n",
        "#if generate_stylegan2_ada or generate_stylegan2_ext:\n",
        "  import dnnlib\n",
        "  import dnnlib.tflib as tflib  \n",
        "  tflib.init_tf()\n",
        "  \n",
        "  import pickle\n",
        "  network_pkl=files_path[0][1]\n",
        "  #with dnnlib.util.open_url(network_pkl) as fp:\n",
        " #       _G, _D, Gs = pickle.load(fp)\n",
        "  _G, _D, Gs = pickle.load(open(network_pkl, \"rb\"))\n",
        "\n",
        "  if generate_tf2_npy:\n",
        "    import numpy as np\n",
        "    data = {}\n",
        "\n",
        "#    import pretrained_networks\n",
        "#    g, d, Gs_network = pretrained_networks.load_networks('/content/model/2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664.pkl')\n",
        "#    for key in  d.trainables.keys():\n",
        "#        data['disc_'+ key] = d.get_var(key)\n",
        "    #print(_G)\n",
        "    #print(_D)\n",
        "    #print(Gs)\n",
        "    \n",
        "    for key in  _G.trainables.keys():\n",
        "        data[key[key.find('/')+1:]] = _G.get_var(key)\n",
        "    #for key in  Gs.trainables.keys():\n",
        "    #    data[key[key.find('/')+1:]] = Gs.get_var(key)\n",
        "    #for key in  _G.trainables.keys():\n",
        "    #    data[key] = _G.get_var(key)\n",
        "    #for key in  Gs.trainables.keys():\n",
        "    #    data['gens_'+ key] = Gs.get_var(key)\n",
        "\n",
        "    for key in  _D.trainables.keys():\n",
        "        data['disc_'+ key] = _D.get_var(key)\n",
        "    np.save('/content/model/{}.npy'.format(files_path[0][2]), data, allow_pickle=True)\n",
        "    #from google.colab import files\n",
        "    #files.download('/content/model/{}.npy'.format(files_path[0][2]))\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    !cp -r -v \"/content/model/{files_path[0][2]}.npy\" \"/content/gdrive/MyDrive/EEG-GAN-audio-video/models/{files_path[0][2]}.npy\"\n",
        "\n",
        "if generate_wavegan:\n",
        " if generate_drums:\n",
        "  # Load the model\n",
        "  tf.reset_default_graph()\n",
        "  saver = tf.train.import_meta_graph('/content/model/infer/infer.meta')\n",
        "  graph = tf.get_default_graph()\n",
        "  sess = tf.InteractiveSession()\n",
        "  saver.restore(sess, f'/content/model/model.ckpt-18637')\n",
        "  #dim = 100\n",
        "  break_len = 65536\n",
        "\n",
        "  z = graph.get_tensor_by_name('z:0')\n",
        "  G_z = graph.get_tensor_by_name('G_z:0')\n",
        "\n",
        "  import numpy as np\n",
        "  from IPython.display import display, Audio\n",
        "  #from google.colab import files\n",
        "  import scipy.io.wavfile\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "  !mkdir \"./neuralfunk examples\"\n",
        "\n",
        "  def generate_trajectory(n_iter, _z0=None, mov_last=None, jump=0.3, smooth=0.3, include_z0=True):\n",
        "    _z = np.empty((n_iter + int(not include_z0), dim))\n",
        "    _z[0] = _z0 if _z0 is not None else np.random.random(dim)*2-1\n",
        "    mov = mov_last if mov_last is not None else (np.random.random(dim)*2-1)*jump\n",
        "    for i in range(1, len(_z)):\n",
        "        mov = mov*smooth + (np.random.random(dim)*2-1)*jump*(1-smooth)\n",
        "        mov -= (np.abs(_z[i-1] + mov) > 1) * 2 * mov\n",
        "        _z[i] = _z[i-1] + mov\n",
        "    return _z[-n_iter:], mov  \n",
        "\n",
        "!mkdir '/content/out'\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (0.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n",
            "Requirement already satisfied: imageio==2.4.1 in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.1) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: imageio-ffmpeg==0.4.3 in /usr/local/lib/python3.7/dist-packages (0.4.3)\n",
            "Requirement already satisfied: pyspng==0.1.0 in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyspng==0.1.0) (1.19.5)\n",
            "mkdir: cannot create directory ‘/content/out’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUKP12wZTYT7"
      },
      "source": [
        "#generate_and_plot_images_notrunc(generator, seed=396)\n",
        "\n",
        "# not using truncation\n",
        "#generate_and_plot_images(generator, seed=96, w_avg=w_average)\n",
        "\n",
        "# using truncation 0.5\n",
        "#generate_and_plot_images(generator, seed=96, w_avg=w_average, truncation_psi=0.5)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrZhTCe5USvq"
      },
      "source": [
        "#def gen():\n",
        "#  global generator\n",
        "#  seed = 6600\n",
        "#  # creating random latent vector\n",
        "#  rnd = np.random.RandomState(seed)\n",
        "#  __z = rnd.randn(1, 512).astype('float32')\n",
        "#  # running mapping network\n",
        "#  dlatents = generator.mapping_network(__z)  \n",
        "# \n",
        "#  out = generator.synthesis_network(dlatents)\n",
        "#  #converting image/s to uint8\n",
        "#  images = convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n",
        "#gen()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lt3tZX8iYM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a583c9ac-39c1-4cee-c0be-a8519912919b"
      },
      "source": [
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "from mne import io\n",
        "from mne.datasets import sample\n",
        "from mne.minimum_norm import read_inverse_operator, compute_source_psd\n",
        "\n",
        "from mne.connectivity import spectral_connectivity, seed_target_indices\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.7/dist-packages (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwhsStNzSHeW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "f5fe2329-b95d-4055-e936-525dfd991522"
      },
      "source": [
        "sfreq = 512 \n",
        "ch_types=['eeg']*len(ch_names)\n",
        "info = mne.create_info(ch_names = ch_names, sfreq = sfreq, ch_types=ch_types)\n",
        "\n",
        "label_names = ch_names\n",
        "no_names = [''] * len(label_names)\n",
        "\n",
        "from IPython.display import Javascript\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from IPython.display import Javascript\n",
        "import json\n",
        "data_read=False\n",
        "\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "data_read=None\n",
        "data_buffer=None\n",
        "data_analyse=None\n",
        "\n",
        "if generate_stylegan2:#_ada or generate_stylegan2_ext:\n",
        "  from IPython.display import Image\n",
        "  import matplotlib.figure\n",
        "  import imageio\n",
        "  #fps=3\n",
        "  video_out = imageio.get_writer('/content/out/output.mp4', mode='I', fps=fps, codec='libx264', bitrate='16M')\n",
        "\n",
        "  js_image = \"\"\n",
        "  from PIL import ImageFont, ImageDraw\n",
        "\n",
        "  if generate_stylegan2_rosasalberto_tf_2_x:\n",
        "    __z = None\n",
        "    dlatents = None\n",
        "  elif generate_stylegan2_moono_tf_2_x:\n",
        "    seed = 6600\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    latents = rnd.randn(1, g_clone.z_dim)\n",
        "    labels = rnd.randn(1, g_clone.labels_dim)\n",
        "    latents = latents.astype(np.float32)\n",
        "    labels = labels.astype(np.float32)\n",
        "    #print([latents, labels])\n",
        "    #image_out = g_clone([latents, labels], training=False, truncation_psi=0.5)\n",
        "    #image_out = postprocess_images(image_out)\n",
        "    #image_out = image_out.numpy()\n",
        "    #print(image_out)\n",
        "  else:\n",
        "   Gs_kwargs = dnnlib.EasyDict()\n",
        "   #Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False)\n",
        "   Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "   Gs_kwargs.randomize_noise = False\n",
        "   _z1 = None\n",
        "\n",
        "if generate_wavegan:\n",
        "  _G_z = None\n",
        "  _G_z_full = None\n",
        "  _G_z_full2 = None\n",
        "  _z = None\n",
        "\n",
        "samples=0\n",
        "\n",
        "from time import perf_counter\n",
        "time100=perf_counter()\n",
        "time111=perf_counter()\n",
        "\n",
        "last_time=0\n",
        "def target_func1(comm, msg):\n",
        "  time000=perf_counter()\n",
        "  #import dnnlib \n",
        "  #import dnnlib.tflib as tflib \n",
        "  #import PIL.Image \n",
        "  #from tqdm import tqdm\n",
        "  ##global _G, _D, Gs\n",
        "  #tflib.init_tf()\n",
        "  #with dnnlib.util.open_url(network_pkl) as fp:\n",
        "  #   _G, _D, Gs = pickle.load(fp)\n",
        "\n",
        "  # Only send the response if it's the data we are expecting.\n",
        "  #if msg['content']['data'] == 'the data':\n",
        "  #  comm.send({\n",
        "  #        'response': 'got comm open!',\n",
        "  #      }, None, msg['buffers']);\n",
        "  #  print(msg['buffers'])\n",
        "  #else:\n",
        "    #print(msg['content']['data'])\n",
        "    #data_read=True\n",
        "  global last_time\n",
        "  global time100\n",
        "  global samples\n",
        "  #array_to_receive_as_json = '[[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0]]'\n",
        "  array_to_receive_as_json = msg['content']['data']\n",
        "  #global data_read\n",
        "  data_read = json.loads(array_to_receive_as_json)\n",
        "  #print('got data')\n",
        "  #print(data_read)\n",
        "  new_data_len=len(data_read[0])\n",
        "  #print(new_data_len)\n",
        "  samples=samples+new_data_len#len(data_analyse[0])\n",
        "  time110=perf_counter()\n",
        "  out_text=f'{(samples):7.0f}'+' sam, '\n",
        "  out_text=out_text+f'{(new_data_len):4.0f}'+\" sam/pac, \"\n",
        "  out_text=out_text+f'{(time110-time100):7.2f}'+\" sec, \"\n",
        "  out_text=out_text+f'{(samples/(time110-time100)):7.2f}'+' sam/sec'\n",
        "  out_text=out_text+f'{(time110-time100)-last_time:7.2f}'+\" sec, \"\n",
        "  out_text=out_text+f'{(new_data_len/((time110-time100)-last_time)):7.2f}'+' sam/sec'\n",
        "  last_time=(time110-time100)\n",
        "  #comm.send({\n",
        "  #        'response': out_text,\n",
        "  #      }, None, msg['buffers']);\n",
        "  #print(out_text)\n",
        "  global label_names,ch_locations,info,bands,duration,overlap,methods,uVperStep,sfreq,dim\n",
        "  #print(duration)\n",
        "  \n",
        "  if not (data_read is None):\n",
        "      #print('read_data-data_read')\n",
        "      #print(len(data_read[0]))\n",
        "      global data_buffer, data_analyse\n",
        "      if data_buffer is None:\n",
        "        data_buffer=data_read\n",
        "      else:\n",
        "        data_buffer=np.concatenate((data_buffer,data_read),axis=1)\n",
        "      data_read = None\n",
        "\n",
        "      data_buffer_len=len(data_buffer[0])\n",
        "      #print(data_buffer_len)\n",
        "      if (int(duration*sfreq)+1)>(int(sfreq/fps)):\n",
        "        data_slice_len=int(duration*sfreq)+1\n",
        "      else:\n",
        "        data_slice_len=int(sfreq/fps)+1\n",
        "      #print(data_slice_len)\n",
        "      if data_buffer_len>data_slice_len:\n",
        "        data_buffer=data_buffer[0:len(data_buffer),data_buffer_len-data_slice_len:data_buffer_len]\n",
        "      #print(len(data_buffer[0]))\n",
        "      #print(data_slice_len)\n",
        "      if len(data_buffer[0])==data_slice_len:\n",
        "        data_analyse=data_buffer\n",
        "      #data_buffer=data_analyse\n",
        "      #print('read_data-data_analyse')\n",
        "      #print(len(data_analyse[0]))\n",
        "  \n",
        "  #if False: \n",
        "  #if True: \n",
        "  if not(data_analyse is None):\n",
        "    #if (time111-time000)>=(1/fps):\n",
        "      time111=perf_counter()\n",
        "      data_uv = [0]*len(label_names)\n",
        "      for j in range(len(label_names)):\n",
        "        data_uv[j]=[0]*len(data_analyse[ch_locations[j]])\n",
        "        for i in range(len(data_analyse[ch_locations[j]])):\n",
        "          data_uv[j][i] = data_analyse[ch_locations[j]][i] * uVperStep * 2\n",
        "      data_analyse=None\n",
        "  \n",
        "      time002=perf_counter()\n",
        "      #print (f'002: {(time002-time000):.1f}s')\n",
        "      raw = mne.io.RawArray(data_uv, info, verbose=50)\n",
        "      time003=perf_counter()\n",
        "      #print (f'003: {(time003-time000):.1f}s')\n",
        "      datas=[]\n",
        "      for band in range(len(bands)):\n",
        "        datas.append(raw)\n",
        "      time004=perf_counter()\n",
        "      epochs = []\n",
        "      #print (f'004: {(time004-time000):.1f}s')\n",
        "      for band in range(len(bands)):\n",
        "        epochs.append(mne.make_fixed_length_epochs(datas[band], duration=duration, preload=True, overlap=overlap, verbose=50))\n",
        "      time005=perf_counter()\n",
        "      #print (f'005: {(time005-time000):.1f}s')\n",
        "      n_generate=int((float(len(data_uv[0]))/float(sfreq))/duration)\n",
        "      n_generate=1\n",
        "      part_len = 10\n",
        "      #dim = 512\n",
        "\n",
        "      n_parts = n_generate//part_len\n",
        "      if n_generate%part_len>0:\n",
        "        n_parts=n_parts+1\n",
        "    \n",
        "      vol=1\n",
        "      #vol=0.1\n",
        "    \n",
        "      psd_array=np.random.rand(part_len, dim) \n",
        "      time006=perf_counter()\n",
        "      #print (f'006: {(time006-time000):.1f}s')\n",
        "    \n",
        "      for j in range(n_parts): # display separate audio for each break\n",
        "        for i in range(part_len): # display separate audio for each break\n",
        "            ji = j * part_len + i\n",
        "            \n",
        "            if (i==0) and (n_generate-ji<part_len):\n",
        "                psd_array=np.random.rand((n_generate-ji), dim) \n",
        "        \n",
        "            sfreq = raw.info['sfreq']  # the sampling frequency\n",
        "            \n",
        "            psds=np.zeros(dim)\n",
        "            \n",
        "            for method in range(len(methods)):\n",
        "             for band in range(len(bands)):\n",
        "              fmin=bands[band][0]\n",
        "              fmax=bands[band][1]\n",
        "              time0071=perf_counter()\n",
        "              #print (f'0071: {(time0071-time000):.1f}s')\n",
        "              #if band == 0:\n",
        "              con, freqs, times, n_epochs, n_tapers = spectral_connectivity(\n",
        "                epochs[band][ji:ji+1], method=methods[method], mode='multitaper', sfreq=sfreq, fmin=fmin,\n",
        "                fmax=fmax, faverage=True, mt_adaptive=True, n_jobs=10, verbose=50)\n",
        "              time007=perf_counter()\n",
        "              #print (f'007: {(time007-time000):.1f}s')\n",
        "              psds_shift1=int(round(method*len(bands)+band)*(len(ch_names)*(len(ch_names)-1)/2))\n",
        "              ji1=0\n",
        "              for j1 in range(0,len(ch_names)): # display separate audio for each break\n",
        "                for i1 in range(0,j1): # display separate audio for each break\n",
        "                  psds[ji1+psds_shift1]=(con[j1][i1][0]-0.5)*1\n",
        "                  ji1 = ji1+1\n",
        "            psd_array[i]=psds\n",
        "            if (i==part_len-1) or (ji==n_generate-1) :\n",
        "              if generate_wavegan:\n",
        "                global G_z, z, _G_z, _G_z_full, _G_z_full2#, _z\n",
        "                _z = psd_array * vol\n",
        "                _G_z = sess.run(G_z, {z: _z})[:,:,0]\n",
        "                if j==0:\n",
        "                  _G_z_full=_G_z\n",
        "                else:\n",
        "                  _G_z_full=np.append(_G_z_full,_G_z)\n",
        "                if _G_z_full2 is None:\n",
        "                  _G_z_full2=_G_z_full\n",
        "                else:\n",
        "                  _G_z_full2=np.append(_G_z_full2,_G_z_full)\n",
        "                                    \n",
        "                if (ji==n_generate-1) :\n",
        "\n",
        "                    buffer = BytesIO()\n",
        "                    scipy.io.wavfile.write(buffer, hz, _G_z_full.flatten()) # change rate for different tempo\n",
        "                    #wave.open(buffer, mode='wb')\n",
        "\n",
        "                    buffer.seek(0)\n",
        "                    mysound = buffer.getvalue()   \n",
        "                    encoded= \"data:audio/wav;base64,\"+base64.b64encode(mysound).decode()\n",
        "\n",
        "                    time110=perf_counter()\n",
        "                    #print (f'110: {(time110-time000):.1f}s')\n",
        "                    #js_image=js\n",
        "                    comm.send({\n",
        "                      'response': encoded,\n",
        "                      }, None, msg['buffers']);\n",
        "                    break\n",
        "    \n",
        "                  #encoded = base64.b64encode(image_asarray).decode('ascii')\n",
        "                  #js='''this.photo.src = \"data:image/png;base64,{0}\"'''.format(encoded)\n",
        "\n",
        "                  \n",
        "                  #js='''senderChannel.postMessage(\"{0}\")'''.format(encoded)\n",
        "                    #js='''playAudio1(\"{0}\",{1},{2})'''.format(encoded,xsize,ysize)\n",
        "                    #js_image=js\n",
        "\n",
        "              if generate_stylegan2:#_ada or generate_stylegan2_ext:\n",
        "               if generate_stylegan2_rosasalberto_tf_2_x:\n",
        "                global generator, dlatents, __z\n",
        "\n",
        "                #seed = 6600\n",
        "                # creating random latent vector\n",
        "                #rnd = np.random.RandomState(seed)\n",
        "                #__z = rnd.randn(1, 512).astype('float32')\n",
        "                # running mapping network\n",
        "                time1101=perf_counter()\n",
        "                #print (f'1101: {(time1101-time000):.1f}s')\n",
        "                #dlatents = generator.mapping_network(__z)  \n",
        "                time1102=perf_counter()\n",
        "                #print (f'1102: {(time1102-time000):.1f}s')\n",
        " \n",
        "                __z = psd_array * vol\n",
        "                dlatents = generator.mapping_network(__z)\n",
        "                time1103=perf_counter()\n",
        "                #print (f'1103: {(time1103-time000):.1f}s')\n",
        "                image_out = generator.synthesis_network(dlatents)\n",
        "                time1104=perf_counter()\n",
        "                #print (f'1104: {(time1104-time000):.1f}s')\n",
        "                #converting image/s to uint8\n",
        "                img = convert_images_to_uint8(image_out, nchw_to_nhwc=True, uint8_cast=True)\n",
        "                #plotting images\n",
        "                #ax[i].axis('off')\n",
        "                #img_plot = ax[i].imshow(img.numpy()[0])   \n",
        "                time1105=perf_counter()\n",
        "                #print (f'1105: {(time1105-time000):.1f}s')\n",
        "                #images=[img.numpy()[0]]\n",
        "                images=img.numpy()\n",
        "               elif generate_stylegan2_moono_tf_2_x:\n",
        "                 global g_clone, latents, labels\n",
        "                 latents = psd_array * vol\n",
        "                 image_out = g_clone([latents, labels], training=False, truncation_psi=0.5)\n",
        "                 image_out = postprocess_images(image_out)\n",
        "                 image = image_out.numpy()\n",
        "               else:\n",
        "                global _G, _D, Gs, Gs_kwargs, _z1\n",
        "                _z1 = psd_array * vol\n",
        "                time1101=perf_counter()\n",
        "                #print (f'1101: {(time1101-time000):.1f}s')\n",
        "                images = Gs.run(_z1, None, **Gs_kwargs) # [minibatch, height, width, channel]\n",
        "                time1102=perf_counter()\n",
        "                #print (f'1102: {(time1102-time000):.1f}s')\n",
        "               if True:\n",
        "                for image in images:\n",
        "                  time1110=perf_counter()\n",
        "                  #print (f'1110: {(time1110-time000):.1f}s')\n",
        "                  #print(image)\n",
        "                  image_pil=PIL.Image.fromarray(image, 'RGB')\n",
        "                  #print(image_pil)\n",
        "                  image_asarray=np.asarray(image_pil)\n",
        "                  #print(image_asarray)\n",
        "                  time1111=perf_counter()\n",
        "                  #print (f'1111: {(time1111-time000):.1f}s')\n",
        "                  global video_out\n",
        "                  #video_out.append_data(image_asarray)\n",
        "                  time1112=perf_counter()\n",
        "                  #print (f'1112: {(time1112-time000):.1f}s')\n",
        "                  img=image_pil.resize((xsize,ysize),PIL.Image.ANTIALIAS)\n",
        "                  #print(img)\n",
        "                  time1113=perf_counter()\n",
        "                  #print (f'1113: {(time1113-time000):.1f}s')\n",
        "                  buffer = BytesIO()\n",
        "                  img.save(buffer,format=\"JPEG\")                  #Enregistre l'image dans le buffer\n",
        "                  #img.save(buffer,format=\"PNG\")                  #Enregistre l'image dans le buffer\n",
        "                  buffer.seek(0)\n",
        "                  time1114=perf_counter()\n",
        "                  #print (f'1114: {(time1114-time000):.1f}s')\n",
        "                  myimage = buffer.getvalue()   \n",
        "                  encoded= \"data:image/jpeg;base64,\"+base64.b64encode(myimage).decode()\n",
        "                   #encoded= \"data:image/png;base64,\"+base64.b64encode(myimage).decode()\n",
        "                  js='''displayPhoto1(\"{0}\",{1},{2})'''.format(encoded,xsize,ysize)\n",
        "                if (ji==n_generate-1) :\n",
        "                    time110=perf_counter()\n",
        "                    #print (f'110: {(time110-time000):.1f}s')\n",
        "                    #js_image=js\n",
        "                    comm.send({\n",
        "                      'response': encoded,\n",
        "                      }, None, msg['buffers']);\n",
        "                    break\n",
        "\n",
        "    #if not(js_image==\"\"):\n",
        "    #  js=js_image\n",
        "    #  js_image=\"\"\n",
        "    #  eval_js(js)\n",
        "#      if True:\n",
        "      if False:\n",
        "                    time111=perf_counter()\n",
        "                    print (f'000: {(time111-time000):.1f}s, '+\n",
        "                      f'001: {(time111-time001):.1f}s, '+\n",
        "                      f'110: {(time111-time110):.1f}s, '+\n",
        "                      f'001-000: {(time001-time000):.1f}s, {(time001-time000)*100/(time111-time000):.0f}%, '+\n",
        "                      f'110-001: {(time110-time001):.1f}s, {(time110-time001)*100/(time111-time000):.0f}%. '+\n",
        "                      f'111-110: {(time111-time110):.1f}s, {(time111-time110)*100/(time111-time000):.0f}%')\n",
        "\n",
        "data_read=False\n",
        "get_ipython().kernel.comm_manager.register_target('comm_target1', target_func1)\n",
        "#target_func1('{1}','{1}')\n",
        "#for i in range(100):\n",
        "#  get_ipython().kernel.comm_manager.register_target(str(i), target_func1)\n",
        "\n",
        "Javascript('''\n",
        "//Joshua Brewster, GPL (copyleft)\n",
        "\n",
        "//import 'regenerator-runtime/runtime' //For async functions on node\\\\\n",
        "\n",
        " class eeg32 { //Contains structs and necessary functions/API calls to analyze serial data for the FreeEEG32\n",
        "\n",
        "    constructor(\n",
        "\t\tonDecodedCallback = this.onDecodedCallback,\n",
        "\t\tonConnectedCallback = this.onConnectedCallback,\n",
        "\t\tonDisconnectedCallback = this.onDisconnectedCallback,\n",
        "\t\tCustomDecoder = this.decode,\n",
        "\t\tbaudrate = 921600//115200\n",
        "\t\t) {\n",
        "\n",
        "\t\tthis.onDecodedCallback = onDecodedCallback;\n",
        "\t\tthis.onConnectedCallback = onConnectedCallback;\n",
        "\t\tthis.onDisconnectedCallback = onDisconnectedCallback;\n",
        "\t\tthis.decode = CustomDecoder;\n",
        "\t\t//Free EEG 32 data structure:\n",
        "        \n",
        "        //    [stop byte, start byte, counter byte, 32x3 channel data bytes (24 bit), 3x2 accelerometer data bytes, stop byte, start byte...] Gyroscope not enabled yet but would be printed after the accelerometer..\n",
        "        //    Total = 105 bytes/line\n",
        "        \n",
        "\t\tthis.connected = false;\n",
        "\t\tthis.subscribed = false;\n",
        "        this.buffer = [];\n",
        "        this.startByte = 160; // Start byte value\n",
        "\t\tthis.stopByte = 192; // Stop byte value\n",
        "\t\tthis.searchString = new Uint8Array([this.stopByte,this.startByte]); //Byte search string\n",
        "\t\tthis.readRate = 16.666667; //Throttle EEG read speed. (1.953ms/sample min @103 bytes/line)\n",
        "\t\tthis.readBufferSize = 2000; //Serial read buffer size, increase for slower read speeds (~1030bytes every 20ms) to keep up with the stream (or it will crash)\n",
        "\n",
        "\t\tthis.sps = 512; // Sample rate\n",
        "\t\tthis.nChannels = 32;\n",
        "\t\tthis.nPeripheralChannels = 6; // accelerometer and gyroscope (2 bytes * 3 coordinates each)\n",
        "\t\tthis.updateMs = 1000/this.sps; //even spacing\n",
        "\t\tthis.stepSize = 1/Math.pow(2,24);\n",
        "\t\tthis.vref = 2.50; //2.5V voltage ref +/- 250nV\n",
        "\t\tthis.gain = 8;\n",
        "\n",
        "\t\tthis.vscale = (this.vref/this.gain)*this.stepSize; //volts per step.\n",
        "\t\tthis.uVperStep = 1000000 * ((this.vref/this.gain)*this.stepSize); //uV per step.\n",
        "\t\tthis.scalar = 1/(1000000 / ((this.vref/this.gain)*this.stepSize)); //steps per uV.\n",
        "\n",
        "\t\tthis.maxBufferedSamples = this.sps*60*2; //max samples in buffer this.sps*60*nMinutes = max minutes of data\n",
        "\t\t\n",
        "\t\tthis.data = { //Data object to keep our head from exploding. Get current data with e.g. this.data.A0[this.data.count-1]\n",
        "\t\t\tcount: 0,\n",
        "\t\t\tstartms: 0,\n",
        "\t\t\tms: [],\n",
        "\t\t\t'A0': [],'A1': [],'A2': [],'A3': [],'A4': [],'A5': [],'A6': [],'A7': [], //ADC 0\n",
        "\t\t\t'A8': [],'A9': [],'A10': [],'A11': [],'A12': [],'A13': [],'A14': [],'A15': [], //ADC 1\n",
        "\t\t\t'A16': [],'A17': [],'A18': [],'A19': [],'A20': [],'A21': [],'A22': [],'A23': [], //ADC 2\n",
        "\t\t\t'A24': [],'A25': [],'A26': [],'A27': [],'A28': [],'A29': [],'A30': [],'A31': [], //ADC 3\n",
        "\t\t\t'Ax': [], 'Ay': [], 'Az': [], 'Gx': [], 'Gy': [], 'Gz': []  //Peripheral data (accelerometer, gyroscope)\n",
        "\t\t};\n",
        "\n",
        "    this.bufferednewLines = 0;\n",
        "    this.data_slice=[];\n",
        "    this.data_slice_size=512*(5*1/8+0.1);\n",
        "    this.ready_to_send_data = false;\n",
        "    this.data_send_count=0;\n",
        "\n",
        "    this.generate_stylegan2=true;\n",
        "    //this.generate_stylegan2=false;\n",
        "    //this.generate_wavegan=true;\n",
        "    this.generate_wavegan=false;\n",
        "    //data:audio/wav;base64,\n",
        "    //data:image/jpeg;base64,\n",
        "\n",
        "\n",
        "    if(this.generate_wavegan)\n",
        "    {\n",
        "      this.hz=44100;\n",
        "      this.fps=this.hz/(32768*2);\n",
        "      //this.fps=this.hz/(32768);\n",
        "    }\n",
        "    if(this.generate_stylegan2)\n",
        "    {\n",
        "      this.fps=2;\n",
        "    }\n",
        "    this.samples_count=0;\n",
        "    //this.channel=None;\n",
        "\n",
        "\t\tthis.resetDataBuffers();\n",
        "\n",
        "\t\t//navigator.serial utils\n",
        "\t\tif(!navigator.serial){\n",
        "\t\t\tconsole.error(\"`navigator.serial not found! Enable #enable-experimental-web-platform-features in chrome://flags (search 'experimental')\")\n",
        "\t\t}\n",
        "\t\tthis.port = null;\n",
        "\t\tthis.reader = null;\n",
        "\t\tthis.baudrate = baudrate;\n",
        "\n",
        "\t}\n",
        "\t\n",
        "\tresetDataBuffers(){\n",
        "\t\tthis.data.count = 0;\n",
        "\t\tthis.data.startms = 0;\n",
        "\t\tfor(const prop in this.data) {\n",
        "\t\t\tif(typeof this.data[prop] === \"object\"){\n",
        "\t\t\t\tthis.data[prop] = new Array(this.maxBufferedSamples).fill(0);\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tsetScalar(gain=24,stepSize=1/(Math.pow(2,23)-1),vref=4.50) {\n",
        "        this.stepSize = stepSize;\n",
        "\t\tthis.vref = vref; //2.5V voltage ref +/- 250nV\n",
        "\t\tthis.gain = gain;\n",
        "\n",
        "\t\tthis.vscale = (this.vref/this.gain)*this.stepSize; //volts per step.\n",
        "\t\tthis.uVperStep = 1000000 * ((this.vref/this.gain)*this.stepSize); //uV per step.\n",
        "\t\tthis.scalar = 1/(1000000 / ((this.vref/this.gain)*this.stepSize)); //steps per uV.\n",
        "    }\n",
        "\n",
        "\tgetLatestData(channel=\"A0\",count=1) { //Return slice of specified size of the latest data from the specified channel\n",
        "\t\tlet ct = count;\n",
        "\t\tif(ct <= 1) {\n",
        "\t\t\treturn [this.data[channel][this.data.count-1]];\n",
        "\t\t}\n",
        "\t\telse {\n",
        "\t\t\tif(ct > this.data.count) {\n",
        "\t\t\t\tct = this.data.count;\n",
        "\t\t\t}\n",
        "\t\t\treturn this.data[channel].slice(this.data.count-ct,this.data.count);\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "    bytesToInt16(x0,x1){\n",
        "\t\treturn x0 * 256 + x1;\n",
        "    }\n",
        "\n",
        "    int16ToBytes(y){ //Turns a 24 bit int into a 3 byte sequence\n",
        "        return [y & 0xFF , (y >> 8) & 0xFF];\n",
        "    }\n",
        "\n",
        "    bytesToInt24(x0,x1,x2){ //Turns a 3 byte sequence into a 24 bit int\n",
        "        return x0 * 65536 + x1 * 256 + x2;\n",
        "    }\n",
        "\n",
        "    int24ToBytes(y){ //Turns a 24 bit int into a 3 byte sequence\n",
        "        return [y & 0xFF , (y >> 8) & 0xFF , (y >> 16) & 0xFF];\n",
        "    }\n",
        "\n",
        "    decode(buffer = this.buffer) { //returns true if successful, returns false if not\n",
        "\n",
        "\t\tvar needle = this.searchString\n",
        "\t\tvar haystack = buffer;\n",
        "\t\tvar search = this.boyerMoore(needle);\n",
        "\t\tvar skip = search.byteLength;\n",
        "\t\tvar indices = [];\n",
        "\t\tlet newLines = 0;\n",
        "    \n",
        "\t\tfor (var i = search(haystack); i !== -1; i = search(haystack, i + skip)) {\n",
        "\t\t\tindices.push(i);\n",
        "\t\t}\n",
        "\t\t//console.log(indices);\n",
        "\t\tif(indices.length >= 2){\n",
        "\t\t\tfor(let k = 1; k < indices.length; k++) {\n",
        "\t\t\t\tif(indices[k] - indices[k-1] !== 105) {\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t} //This is not a valid sequence going by size, drop sequence and return\n",
        "\t\t\t\telse {\n",
        "\t\t\t\t\tvar line = buffer.slice(indices[k-1],indices[k]+1); //Splice out this line to be decoded\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\t// line[0] = stop byte, line[1] = start byte, line[2] = counter, line[3:99] = ADC data 32x3 bytes, line[100-104] = Accelerometer data 3x2 bytes\n",
        "\n",
        "\t\t\t\t\t//line found, decode.\n",
        "\t\t\t\t\tif(this.data.count < this.maxBufferedSamples){\n",
        "\t\t\t\t\t\tthis.data.count++;\n",
        "\t\t\t\t\t}\n",
        "\n",
        "\t\t\t\t\tif(this.data.count-1 === 0) {this.data.ms[this.data.count-1]= Date.now(); this.data.startms = this.data.ms[0];}\n",
        "\t\t\t\t\telse {\n",
        "\t\t\t\t\t\tthis.data.ms[this.data.count-1]=this.data.ms[this.data.count-2]+this.updateMs;\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tif(this.data.count >= this.maxBufferedSamples) {\n",
        "\t\t\t\t\t\t\tthis.data.ms.splice(0,5120);\n",
        "\t\t\t\t\t\t\tthis.data.ms.push(new Array(5120).fill(0));\n",
        "\t\t\t\t\t\t}\n",
        "\t\t\t\t\t}//Assume no dropped samples\n",
        "\t\t\t\t  var sample_count = line[2];\n",
        "\t\t\t\t  var sample_count_diff = sample_count-this.samples_count;\n",
        "          if(sample_count_diff<0){\n",
        "            sample_count_diff+=256;\n",
        "          }\n",
        "          if(sample_count_diff!=1)\n",
        "          {\n",
        "            console.error(\"dropped samples:\"+sample_count_diff.toString());\n",
        "          }\n",
        "          this.samples_count=sample_count;\n",
        "\n",
        "\t\t\t\t\tfor(var i = 3; i < 99; i+=3) {\n",
        "\t\t\t\t\t\tvar channel = \"A\"+(i-3)/3;\n",
        "\t\t\t\t\t\tthis.data[channel][this.data.count-1]=this.bytesToInt24(line[i],line[i+1],line[i+2]);\n",
        "\t\t\t\t\t\tif(this.data.count >= this.maxBufferedSamples) { \n",
        "\t\t\t\t\t\t\tthis.data[channel].splice(0,5120);\n",
        "\t\t\t\t\t\t\tthis.data[channel].push(new Array(5120).fill(0));//shave off the last 10 seconds of data if buffer full (don't use shift())\n",
        "\t\t\t\t\t\t}\n",
        "\t\t\t\t\t\t\t//console.log(this.data[channel][this.data.count-1],indices[k], channel)\n",
        "\t\t\t\t\t}\n",
        "\n",
        "\t\t\t\t\tthis.data[\"Ax\"][this.data.count-1]=this.bytesToInt16(line[99],line[100]);\n",
        "\t\t\t\t\tthis.data[\"Ay\"][this.data.count-1]=this.bytesToInt16(line[101],line[102]);\n",
        "\t\t\t\t\tthis.data[\"Az\"][this.data.count-1]=this.bytesToInt16(line[103],line[104]);\n",
        "\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tif(this.data.count >= this.maxBufferedSamples) { \n",
        "\t\t\t\t\t\tthis.data[\"Ax\"].splice(0,5120);\n",
        "\t\t\t\t\t\tthis.data[\"Ay\"].splice(0,5120);\n",
        "\t\t\t\t\t\tthis.data[\"Az\"].splice(0,5120);\n",
        "\t\t\t\t\t\tthis.data[\"Ax\"].push(new Array(5120).fill(0))\n",
        "\t\t\t\t\t\tthis.data[\"Ay\"].push(new Array(5120).fill(0))\n",
        "\t\t\t\t\t\tthis.data[\"Az\"].push(new Array(5120).fill(0))\n",
        "\t\t\t\t\t\tthis.data.count -= 5120;\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t\t//console.log(this.data)\n",
        "\t\t\t\t\tnewLines++;\n",
        "\t\t\t\t\t//console.log(indices[k-1],indices[k])\n",
        "\t\t\t\t\t//console.log(buffer[indices[k-1],buffer[indices[k]]])\n",
        "\t\t\t\t\t//indices.shift();\n",
        "\t\t\t\t}\n",
        "\t\t\t\t\n",
        "\t\t\t}\n",
        "\t\t\tif(newLines > 0) buffer.splice(0,indices[indices.length-1]);\n",
        "   \n",
        "\t\t\treturn newLines;\n",
        "\t\t\t//Continue\n",
        "\t\t}\n",
        "\t\t//else {this.buffer = []; return false;}\n",
        "\t}\n",
        "\t//Callbacks\n",
        "\tonDecodedCallback(newLinesInt){\n",
        "\t\t//console.log(\"new samples:\", newLinesInt);\n",
        "    this.bufferednewLines=this.bufferednewLines+newLinesInt;\n",
        "    //if(this.bufferednewLines>this.data_slice_size)\n",
        "    //  {\n",
        "    //    this.bufferednewLines=this.data_slice_size;\n",
        "    //  }\n",
        "    if(this.bufferednewLines>512/this.fps)\n",
        "    {\n",
        "      this.bufferednewLines=512/this.fps;\n",
        "\n",
        "        this.takeandsendSlice(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
        "    }\n",
        "\t\t//console.log(\"this.bufferednewLines:\", this.bufferednewLines);\n",
        "    //this.takeSlice(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
        "    //this.takeandsendSlice(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
        "    //this.takeandsendSliceBroadcast(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
        " \t}\n",
        "\n",
        "\tonConnectedCallback() {\n",
        "\t\tconsole.log(\"port connected!\");\n",
        "\t}\n",
        "\n",
        "\tonDisconnectedCallback() {\n",
        "\t\tconsole.log(\"port disconnected!\");\n",
        "\t}\n",
        "\n",
        "\tonReceive(value){\n",
        "\t\tthis.buffer.push(...value);\n",
        "\n",
        "\t\tlet newLines = this.decode(this.buffer);\n",
        "\t\t//console.log(this.data)\n",
        "\t\t//console.log(\"decoding... \", this.buffer.length)\n",
        "\t\tif(newLines !== false && newLines !== 0 && !isNaN(newLines) ) this.onDecodedCallback(newLines);\n",
        "\t}\n",
        "\n",
        "\tasync onPortSelected(port,baud=this.baudrate) {\n",
        "\t\ttry{\n",
        "\t\t\ttry {\n",
        "\t\t\t\tawait port.open({ baudRate: baud, bufferSize: this.readBufferSize });\n",
        "\t\t\t\tthis.onConnectedCallback();\n",
        "\t\t\t\tthis.connected = true;\n",
        "\t\t\t\tthis.subscribed = true;\n",
        "\t\t\t\tthis.subscribe(port);//this.subscribeSafe(port);\n",
        "\t\t\n",
        "\t\t\t} //API inconsistency in syntax between linux and windows\n",
        "\t\t\tcatch {\n",
        "\t\t\t\tawait port.open({ baudrate: baud, buffersize: this.readBufferSize });\n",
        "\t\t\t\tthis.onConnectedCallback();\n",
        "\t\t\t\tthis.connected = true;\n",
        "\t\t\t\tthis.subscribed = true;\n",
        "\t\t\t\tthis.subscribe(port);//this.subscribeSafe(port);\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t\tcatch(err){\n",
        "\t\t\tconsole.log(err);\n",
        "\t\t\tthis.connected = false;\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tasync subscribe(port){\n",
        "\t\tif (this.port.readable && this.subscribed === true) {\n",
        "\t\t\tthis.reader = port.readable.getReader();\n",
        "\t\t\tconst streamData = async () => {\n",
        "\t\t\t\ttry {\n",
        "\t\t\t\t\tconst { value, done } = await this.reader.read();\n",
        "\t\t\t\t\tif (done || this.subscribed === false) {\n",
        "\t\t\t\t\t\t// Allow the serial port to be closed later.\n",
        "\t\t\t\t\t\tawait this.reader.releaseLock();\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t\tif (value) {\n",
        "\t\t\t\t\t\t//console.log(value.length);\n",
        "\t\t\t\t\t\ttry{\n",
        "\t\t\t\t\t\t\tthis.onReceive(value);\n",
        "\t\t\t\t\t\t}\n",
        "\t\t\t\t\t\tcatch (err) {console.log(err)}\n",
        "\t\t\t\t\t\t//console.log(\"new Read\");\n",
        "\t\t\t\t\t\t//console.log(this.decoder.decode(value));\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t\tif(this.subscribed === true) {\n",
        "\t\t\t\t\t\tsetTimeout(()=>{streamData();}, this.readRate);//Throttled read 1/512sps = 1.953ms/sample @ 103 bytes / line or 1030bytes every 20ms\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t} catch (error) {\n",
        "\t\t\t\t\tconsole.log(error);// TODO: Handle non-fatal read error.\n",
        "                    if(error.message.includes('framing') || error.message.includes('overflow') || error.message.includes('Overflow') || error.message.includes('break')) {\n",
        "                        this.subscribed = false;\n",
        "                        setTimeout(async ()=>{\n",
        "\t\t\t\t\t\t\ttry{\n",
        "                            if (this.reader) {\n",
        "                                await this.reader.releaseLock();\n",
        "                                this.reader = null;\n",
        "                            }\n",
        "\t\t\t\t\t\t\t} catch (er){ console.error(er);}\n",
        "                            this.subscribed = true; \n",
        "                            this.subscribe(port);\n",
        "                            //if that fails then close port and reopen it\n",
        "                        },30); //try to resubscribe \n",
        "                    } else if (error.message.includes('parity') || error.message.includes('Parity') || error.message.includes('overrun') ) {\n",
        "                        if(this.port){\n",
        "                            this.subscribed = false;\n",
        "                            setTimeout(async () => {\n",
        "\t\t\t\t\t\t\t\ttry{\n",
        "                                if (this.reader) {\n",
        "                                    await this.reader.releaseLock();\n",
        "                                    this.reader = null;\n",
        "                                }\n",
        "                                await port.close();\n",
        "\t\t\t\t\t\t\t\t} catch (er){ console.error(er);}\n",
        "                                //this.port = null;\n",
        "                                this.connected = false;\n",
        "                                setTimeout(()=>{this.onPortSelected(this.port)},100); //close the port and reopen\n",
        "                            }, 50);\n",
        "                        }\n",
        "                    }\n",
        "                     else {\n",
        "                        this.closePort();\t\n",
        "                    }\t\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t\tstreamData();\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\t//Unfinished\n",
        "\tasync subscribeSafe(port) { //Using promises instead of async/await to cure hangs when the serial update does not meet tick requirements\n",
        "\t\tvar readable = new Promise((resolve,reject) => {\n",
        "\t\t\twhile(this.port.readable && this.subscribed === true){\n",
        "\t\t\t\tthis.reader = port.readable.getReader();\n",
        "\t\t\t\tvar looper = true;\n",
        "\t\t\t\tvar prom1 = new Promise((resolve,reject) => {\n",
        "\t\t\t\t\treturn this.reader.read();\n",
        "\t\t\t\t});\n",
        "\n",
        "\t\t\t\tvar prom2 = new Promise((resolve,reject) => {\n",
        "\t\t\t\t\tsetTimeout(resolve,100,\"readfail\");\n",
        "\t\t\t\t});\n",
        "\t\t\t\twhile(looper === true ) {\n",
        "\t\t\t\t\t//console.log(\"reading...\");\n",
        "\t\t\t\t\tPromise.race([prom1,prom2]).then((result) => {\n",
        "\t\t\t\t\t\tconsole.log(\"newpromise\")\n",
        "\t\t\t\t\t\tif(result === \"readfail\"){\n",
        "\t\t\t\t\t\t\tconsole.log(result);\n",
        "\t\t\t\t\t\t}\n",
        "\t\t\t\t\t\telse{\n",
        "\t\t\t\t\t\t\tconst {value, done} = result;\n",
        "\t\t\t\t\t\t\tif(done === true || this.subscribed === true) { var donezo = new Promise((resolve,reject) => {\n",
        "\t\t\t\t\t\t\t\tresolve(this.reader.releaseLock())}).then(() => {\n",
        "\t\t\t\t\t\t\t\t\tlooper = false;\n",
        "\t\t\t\t\t\t\t\t\treturn;\n",
        "\t\t\t\t\t\t\t\t});\n",
        "\t\t\t\t\t\t\t}\n",
        "\t\t\t\t\t\t\telse{\n",
        "\t\t\t\t\t\t\t\tthis.onReceive(value);\n",
        "\t\t\t\t\t\t\t}\n",
        "\t\t\t\t\t\t}\n",
        "\t\t\t\t\t});\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t\tresolve(\"not readable\");\n",
        "\t\t});\n",
        "\t}\n",
        "\n",
        "\tasync closePort(port=this.port) {\n",
        "\t\t//if(this.reader) {this.reader.releaseLock();}\n",
        "\t\tif(this.port){\n",
        "\t\t\tthis.subscribed = false;\n",
        "\t\t\tsetTimeout(async () => {\n",
        "\t\t\t\tif (this.reader) {\n",
        "\t\t\t\t\tawait this.reader.releaseLock();\n",
        "\t\t\t\t\tthis.reader = null;\n",
        "\t\t\t\t}\n",
        "\t\t\t\tawait port.close();\n",
        "\t\t\t\tthis.port = null;\n",
        "\t\t\t\tthis.connected = false;\n",
        "\t\t\t\tthis.onDisconnectedCallback();\n",
        "\t\t\t}, 100);\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tasync setupSerialAsync(baudrate=this.baudrate) { //You can specify baudrate just in case\n",
        "\n",
        "\t\tconst filters = [\n",
        "\t\t\t{ usbVendorId: 0x10c4, usbProductId: 0x0043 } //CP2102 filter (e.g. for UART via ESP32)\n",
        "\t\t];\n",
        "\n",
        "\t\tthis.port = await navigator.serial.requestPort();\n",
        "\t\tnavigator.serial.addEventListener(\"disconnect\",(e) => {\n",
        "\t\t\tthis.closePort(this.port);\n",
        "\t\t});\n",
        "\t\tthis.onPortSelected(this.port,baudrate);\n",
        "\n",
        "\t\t//navigator.serial.addEventListener(\"onReceive\", (e) => {console.log(e)});//this.onReceive(e));\n",
        "\n",
        "\t}\n",
        "\n",
        "\n",
        "\t//Boyer Moore fast byte search method copied from https://codereview.stackexchange.com/questions/20136/uint8array-indexof-method-that-allows-to-search-for-byte-sequences\n",
        "\tasUint8Array(input) {\n",
        "\t\tif (input instanceof Uint8Array) {\n",
        "\t\t\treturn input;\n",
        "\t\t} else if (typeof(input) === 'string') {\n",
        "\t\t\t// This naive transform only supports ASCII patterns. UTF-8 support\n",
        "\t\t\t// not necessary for the intended use case here.\n",
        "\t\t\tvar arr = new Uint8Array(input.length);\n",
        "\t\t\tfor (var i = 0; i < input.length; i++) {\n",
        "\t\t\tvar c = input.charCodeAt(i);\n",
        "\t\t\tif (c > 127) {\n",
        "\t\t\t\tthrow new TypeError(\"Only ASCII patterns are supported\");\n",
        "\t\t\t}\n",
        "\t\t\tarr[i] = c;\n",
        "\t\t\t}\n",
        "\t\t\treturn arr;\n",
        "\t\t} else {\n",
        "\t\t\t// Assume that it's already something that can be coerced.\n",
        "\t\t\treturn new Uint8Array(input);\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "\tboyerMoore(patternBuffer) {\n",
        "\t\t// Implementation of Boyer-Moore substring search ported from page 772 of\n",
        "\t\t// Algorithms Fourth Edition (Sedgewick, Wayne)\n",
        "\t\t// http://algs4.cs.princeton.edu/53substring/BoyerMoore.java.html\n",
        "\t\t\n",
        "//\t\tUSAGE:\n",
        "\t\t\t// needle should be ASCII string, ArrayBuffer, or Uint8Array\n",
        "\t\t\t// haystack should be an ArrayBuffer or Uint8Array\n",
        "//\t\t\tvar search = boyerMoore(needle);\n",
        "//\t\t\tvar skip = search.byteLength;\n",
        "//\t\t\tvar indices = [];\n",
        "//\t\t\tfor (var i = search(haystack); i !== -1; i = search(haystack, i + skip)) {\n",
        "//\t\t\t\tindices.push(i);\n",
        "//\t\t\t}\n",
        "\t\t\n",
        "\t\tvar pattern = this.asUint8Array(patternBuffer);\n",
        "\t\tvar M = pattern.length;\n",
        "\t\tif (M === 0) {\n",
        "\t\t\tthrow new TypeError(\"patternBuffer must be at least 1 byte long\");\n",
        "\t\t}\n",
        "\t\t// radix\n",
        "\t\tvar R = 256;\n",
        "\t\tvar rightmost_positions = new Int32Array(R);\n",
        "\t\t// position of the rightmost occurrence of the byte c in the pattern\n",
        "\t\tfor (var c = 0; c < R; c++) {\n",
        "\t\t\t// -1 for bytes not in pattern\n",
        "\t\t\trightmost_positions[c] = -1;\n",
        "\t\t}\n",
        "\t\tfor (var j = 0; j < M; j++) {\n",
        "\t\t\t// rightmost position for bytes in pattern\n",
        "\t\t\trightmost_positions[pattern[j]] = j;\n",
        "\t\t}\n",
        "\t\tvar boyerMooreSearch = (txtBuffer, start, end) => {\n",
        "\t\t\t// Return offset of first match, -1 if no match.\n",
        "\t\t\tvar txt = this.asUint8Array(txtBuffer);\n",
        "\t\t\tif (start === undefined) start = 0;\n",
        "\t\t\tif (end === undefined) end = txt.length;\n",
        "\t\t\tvar pat = pattern;\n",
        "\t\t\tvar right = rightmost_positions;\n",
        "\t\t\tvar lastIndex = end - pat.length;\n",
        "\t\t\tvar lastPatIndex = pat.length - 1;\n",
        "\t\t\tvar skip;\n",
        "\t\t\tfor (var i = start; i <= lastIndex; i += skip) {\n",
        "\t\t\t\tskip = 0;\n",
        "\t\t\t\tfor (var j = lastPatIndex; j >= 0; j--) {\n",
        "\t\t\t\tvar c = txt[i + j];\n",
        "\t\t\t\tif (pat[j] !== c) {\n",
        "\t\t\t\t\tskip = Math.max(1, j - right[c]);\n",
        "\t\t\t\t\tbreak;\n",
        "\t\t\t\t}\n",
        "\t\t\t\t}\n",
        "\t\t\t\tif (skip === 0) {\n",
        "\t\t\t\treturn i;\n",
        "\t\t\t\t}\n",
        "\t\t\t}\n",
        "\t\t\treturn -1;\n",
        "\t\t};\n",
        "\t\tboyerMooreSearch.byteLength = pattern.byteLength;\n",
        "\t\treturn boyerMooreSearch;\n",
        "\t}\n",
        "\t//---------------------end copy/pasted solution------------------------\n",
        "\n",
        "    async  takeandsendSlice(data_slice_from,data_slice_to) {\n",
        "        //this.lastnewLines=this.bufferednewLines;\n",
        "     //if(this.ready_to_send_data&&this.bufferednewLines){//&&this.data_slice[0].length)\n",
        "     if(this.ready_to_send_data&&this.bufferednewLines)//&&this.data_slice[0].length)\n",
        "     {\n",
        "      //this.ready_to_send_data = false;\n",
        "      this.data_slice = [\n",
        "        //device.data.ms.slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+0].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+1].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+2].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+3].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+4].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+5].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+6].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+7].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+8].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+9].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+10].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+11].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+12].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+13].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+14].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+15].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+16].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+17].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+18].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+19].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+20].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+21].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+22].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+23].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+24].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+25].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+26].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+27].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+28].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+29].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+30].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+31].slice(data_slice_from,data_slice_to)\n",
        "        ];\n",
        "  this.bufferednewLines=0;\n",
        "  //const buffer = new Uint8Array(10);\n",
        "  //for (let i = 0; i < buffer.byteLength; ++i) {\n",
        "  //  buffer[i] = i\n",
        "  //}\n",
        "  var array_to_send_as_json = JSON.stringify(this.data_slice);\n",
        "  //document.body.appendChild(document.createTextNode('sending ready'));\n",
        "  this.data_send_count++;\n",
        "  //if(this.channel==None)\n",
        "  //{\n",
        "  //  this.channel = await google.colab.kernel.comms.open('comm_target1', array_to_send_as_json, []);\n",
        "    //this.channel = await google.colab.kernel.comms.open(this.data_send_count.toString(), array_to_send_as_json, []);\n",
        "  //} else \n",
        "  //{\n",
        "    //this.channel.send(this.data_send_count.toString())\n",
        "  //}\n",
        "  //document.body.appendChild(document.createTextNode(array_to_send_as_json));\n",
        "  const channel = await google.colab.kernel.comms.open('comm_target1', array_to_send_as_json, []);\n",
        "  //const channel = await google.colab.kernel.comms.open('comm_target1', 'the data', [buffer.buffer]);\n",
        "  let success = false;\n",
        "  for await (const message of channel.messages) {\n",
        "    if (message.data.response == 'got comm open!') {\n",
        "      const responseBuffer = new Uint8Array(message.buffers[0]);\n",
        "      for (let i = 0; i < buffer.length; ++i) {\n",
        "        if (responseBuffer[i] != buffer[i]) {\n",
        "          console.error('comm buffer different at ' + i);\n",
        "          document.body.appendChild(document.createTextNode('comm buffer different at2 ' + i));\n",
        "          return;\n",
        "        }\n",
        "      }\n",
        "      // Close the channel once the expected message is received. This should\n",
        "      // cause the messages iterator to complete and for the for-await loop to\n",
        "      // end.\n",
        "      //console.error('comm buffer same ' + responseBuffer);\n",
        "      //document.body.appendChild(document.createTextNode('comm buffer same2 ' + responseBuffer));\n",
        "      channel.close();\n",
        "    }\n",
        "    if (this.generate_wavegan)\n",
        "    {\n",
        "      await playAudio1(message.data.response);\n",
        "    }\n",
        "    if (this.generate_stylegan2)\n",
        "    {\n",
        "      await displayPhoto1(message.data.response);\n",
        "    }\n",
        "  }\n",
        "      //this.ready_to_send_data = true;\n",
        "  document.body.appendChild(document.createTextNode('done2.'));\n",
        "     } \n",
        "\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "device = new eeg32();\n",
        "\n",
        "    connect = async () => {\n",
        "        await this.device.setupSerialAsync();\n",
        "    }\n",
        "\n",
        "    disconnect = () => {\n",
        "        if (this.ui) this.ui.deleteNode()\n",
        "        this.device.closePort();\n",
        "    }\n",
        "\n",
        "\n",
        "        const canvas = document.createElement('canvas');\n",
        "      const audio = document.createElement('audio');\n",
        "      const audio1 = document.createElement('audio');\n",
        "      const audio2 = document.createElement('audio');\n",
        "\n",
        "          var ctx = canvas.getContext(\"2d\");\n",
        "\n",
        "      var image = new Image();\n",
        "      image.onload = function() {\n",
        "        ctx.drawImage(image, 0, 0);\n",
        "      };\n",
        "const div = document.createElement('div');\n",
        "const btnconnect = document.createElement('button');\n",
        "const btndisconnect = document.createElement('button');\n",
        "const capture = document.createElement('button');\n",
        "                  \n",
        "    async function takePhoto2(quality=1) {\n",
        "      btnconnect.remove();\n",
        "      capture.remove();\n",
        "      device.ready_to_send_data = true;\n",
        "    }\n",
        "\n",
        "    async function takePhoto(quality=1) {\n",
        "\n",
        "      btnconnect.textContent = 'connect';\n",
        "      div.appendChild(btnconnect);\n",
        "      btnconnect.onclick = this.connect;\n",
        "      \n",
        "      btndisconnect.textContent = 'disconnect';\n",
        "      div.appendChild(btndisconnect);\n",
        "      btndisconnect.onclick = this.disconnect;\n",
        "      \n",
        "      capture.textContent = 'Capture';\n",
        "      capture.onclick = takePhoto2;\n",
        "      div.appendChild(capture);\n",
        "     \n",
        "      div.appendChild(canvas);\n",
        "      div.appendChild(audio);\n",
        "      div.appendChild(audio1);\n",
        "      div.appendChild(audio2);\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "         await new Promise((resolve) => capture.onclick = resolve);\n",
        " \n",
        "      btnconnect.remove();\n",
        "      capture.remove();\n",
        "      device.ready_to_send_data = true;\n",
        "    }\n",
        "\n",
        "    async function takePhoto1(quality=1) {  \n",
        "      //var data_slice_send=this.device.data_slice;\n",
        "      //var data_slice_send=[this.device.data_slice[0],this.device.data_slice[1]];\n",
        "      //var data_slice_send=[this.device.data_slice[0]];\n",
        "      var data_slice_send=[[this.device.data_slice[0][0]]];\n",
        "\t  \t//console.log(\"data_slice_send[0].length:\", data_slice_send[0].length);\n",
        "  \t\t//console.log(\"device.bufferednewLines:\", device.bufferednewLines);\n",
        "      device.bufferednewLines=0;\n",
        "      return data_slice_send;      \n",
        "    }\n",
        "\n",
        "    async function displayPhoto1(photodata,photoWidth=400,photoHeight=400) {\n",
        "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
        "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
        "      await displayPhoto2(photodata,photoWidth,photoHeight);\n",
        "    }\n",
        "    async function displayPhoto2(photodata,photoWidth,photoHeight) {\n",
        "      if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
        "      if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
        "     image.src = photodata;\n",
        "    }\n",
        "    var audio_now=0;\n",
        "    async function playAudio1(audiodata,photoWidth=200,photoHeight=200) {\n",
        "      //const canvas = document.createElement('canvas');\n",
        "      canvas.width = photoWidth;\n",
        "      canvas.height = photoHeight;\n",
        "      //audio.controls = true;\n",
        "      //audio.autoplay = true;\n",
        "      audio1.controls = true;\n",
        "      audio1.autoplay = true;\n",
        "      audio2.controls = true;\n",
        "      audio2.autoplay = true;\n",
        "\n",
        "      //canvas.getContext('2d').drawImage(photodata, 0, 0);\n",
        "      //var canvas = document.getElementById(\"c\");\n",
        "      ///var ctx = canvas.getContext(\"2d\");\n",
        "\n",
        "      ///var image = new Image();\n",
        "      ///image.onload = function() {\n",
        "      ///  ctx.drawImage(image, 0, 0);\n",
        "      ///};\n",
        "      //audio.src = audiodata;\n",
        "      //audio.play()\n",
        "      if(audio_now%2==0)\n",
        "      {\n",
        "        audio1.src = audiodata;\n",
        "        audio1.play()\n",
        "      }\n",
        "      else\n",
        "      {\n",
        "        audio2.src = audiodata;\n",
        "        audio2.play()\n",
        "      }\n",
        "      audio_now++;\n",
        "\n",
        "    }\n",
        "    \n",
        "  takePhoto();\n",
        "  data_count=0;\n",
        "\n",
        "''')\n",
        "  \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/javascript": [
              "\n",
              "//Joshua Brewster, GPL (copyleft)\n",
              "\n",
              "//import 'regenerator-runtime/runtime' //For async functions on node\\\n",
              "\n",
              " class eeg32 { //Contains structs and necessary functions/API calls to analyze serial data for the FreeEEG32\n",
              "\n",
              "    constructor(\n",
              "\t\tonDecodedCallback = this.onDecodedCallback,\n",
              "\t\tonConnectedCallback = this.onConnectedCallback,\n",
              "\t\tonDisconnectedCallback = this.onDisconnectedCallback,\n",
              "\t\tCustomDecoder = this.decode,\n",
              "\t\tbaudrate = 921600//115200\n",
              "\t\t) {\n",
              "\n",
              "\t\tthis.onDecodedCallback = onDecodedCallback;\n",
              "\t\tthis.onConnectedCallback = onConnectedCallback;\n",
              "\t\tthis.onDisconnectedCallback = onDisconnectedCallback;\n",
              "\t\tthis.decode = CustomDecoder;\n",
              "\t\t//Free EEG 32 data structure:\n",
              "        \n",
              "        //    [stop byte, start byte, counter byte, 32x3 channel data bytes (24 bit), 3x2 accelerometer data bytes, stop byte, start byte...] Gyroscope not enabled yet but would be printed after the accelerometer..\n",
              "        //    Total = 105 bytes/line\n",
              "        \n",
              "\t\tthis.connected = false;\n",
              "\t\tthis.subscribed = false;\n",
              "        this.buffer = [];\n",
              "        this.startByte = 160; // Start byte value\n",
              "\t\tthis.stopByte = 192; // Stop byte value\n",
              "\t\tthis.searchString = new Uint8Array([this.stopByte,this.startByte]); //Byte search string\n",
              "\t\tthis.readRate = 16.666667; //Throttle EEG read speed. (1.953ms/sample min @103 bytes/line)\n",
              "\t\tthis.readBufferSize = 2000; //Serial read buffer size, increase for slower read speeds (~1030bytes every 20ms) to keep up with the stream (or it will crash)\n",
              "\n",
              "\t\tthis.sps = 512; // Sample rate\n",
              "\t\tthis.nChannels = 32;\n",
              "\t\tthis.nPeripheralChannels = 6; // accelerometer and gyroscope (2 bytes * 3 coordinates each)\n",
              "\t\tthis.updateMs = 1000/this.sps; //even spacing\n",
              "\t\tthis.stepSize = 1/Math.pow(2,24);\n",
              "\t\tthis.vref = 2.50; //2.5V voltage ref +/- 250nV\n",
              "\t\tthis.gain = 8;\n",
              "\n",
              "\t\tthis.vscale = (this.vref/this.gain)*this.stepSize; //volts per step.\n",
              "\t\tthis.uVperStep = 1000000 * ((this.vref/this.gain)*this.stepSize); //uV per step.\n",
              "\t\tthis.scalar = 1/(1000000 / ((this.vref/this.gain)*this.stepSize)); //steps per uV.\n",
              "\n",
              "\t\tthis.maxBufferedSamples = this.sps*60*2; //max samples in buffer this.sps*60*nMinutes = max minutes of data\n",
              "\t\t\n",
              "\t\tthis.data = { //Data object to keep our head from exploding. Get current data with e.g. this.data.A0[this.data.count-1]\n",
              "\t\t\tcount: 0,\n",
              "\t\t\tstartms: 0,\n",
              "\t\t\tms: [],\n",
              "\t\t\t'A0': [],'A1': [],'A2': [],'A3': [],'A4': [],'A5': [],'A6': [],'A7': [], //ADC 0\n",
              "\t\t\t'A8': [],'A9': [],'A10': [],'A11': [],'A12': [],'A13': [],'A14': [],'A15': [], //ADC 1\n",
              "\t\t\t'A16': [],'A17': [],'A18': [],'A19': [],'A20': [],'A21': [],'A22': [],'A23': [], //ADC 2\n",
              "\t\t\t'A24': [],'A25': [],'A26': [],'A27': [],'A28': [],'A29': [],'A30': [],'A31': [], //ADC 3\n",
              "\t\t\t'Ax': [], 'Ay': [], 'Az': [], 'Gx': [], 'Gy': [], 'Gz': []  //Peripheral data (accelerometer, gyroscope)\n",
              "\t\t};\n",
              "\n",
              "    this.bufferednewLines = 0;\n",
              "    this.data_slice=[];\n",
              "    this.data_slice_size=512*(5*1/8+0.1);\n",
              "    this.ready_to_send_data = false;\n",
              "    this.data_send_count=0;\n",
              "\n",
              "    this.generate_stylegan2=true;\n",
              "    //this.generate_stylegan2=false;\n",
              "    //this.generate_wavegan=true;\n",
              "    this.generate_wavegan=false;\n",
              "    //data:audio/wav;base64,\n",
              "    //data:image/jpeg;base64,\n",
              "\n",
              "\n",
              "    if(this.generate_wavegan)\n",
              "    {\n",
              "      this.hz=44100;\n",
              "      this.fps=this.hz/(32768*2);\n",
              "      //this.fps=this.hz/(32768);\n",
              "    }\n",
              "    if(this.generate_stylegan2)\n",
              "    {\n",
              "      this.fps=2;\n",
              "    }\n",
              "    this.samples_count=0;\n",
              "    //this.channel=None;\n",
              "\n",
              "\t\tthis.resetDataBuffers();\n",
              "\n",
              "\t\t//navigator.serial utils\n",
              "\t\tif(!navigator.serial){\n",
              "\t\t\tconsole.error(\"`navigator.serial not found! Enable #enable-experimental-web-platform-features in chrome://flags (search 'experimental')\")\n",
              "\t\t}\n",
              "\t\tthis.port = null;\n",
              "\t\tthis.reader = null;\n",
              "\t\tthis.baudrate = baudrate;\n",
              "\n",
              "\t}\n",
              "\t\n",
              "\tresetDataBuffers(){\n",
              "\t\tthis.data.count = 0;\n",
              "\t\tthis.data.startms = 0;\n",
              "\t\tfor(const prop in this.data) {\n",
              "\t\t\tif(typeof this.data[prop] === \"object\"){\n",
              "\t\t\t\tthis.data[prop] = new Array(this.maxBufferedSamples).fill(0);\n",
              "\t\t\t}\n",
              "\t\t}\n",
              "\t}\n",
              "\n",
              "\tsetScalar(gain=24,stepSize=1/(Math.pow(2,23)-1),vref=4.50) {\n",
              "        this.stepSize = stepSize;\n",
              "\t\tthis.vref = vref; //2.5V voltage ref +/- 250nV\n",
              "\t\tthis.gain = gain;\n",
              "\n",
              "\t\tthis.vscale = (this.vref/this.gain)*this.stepSize; //volts per step.\n",
              "\t\tthis.uVperStep = 1000000 * ((this.vref/this.gain)*this.stepSize); //uV per step.\n",
              "\t\tthis.scalar = 1/(1000000 / ((this.vref/this.gain)*this.stepSize)); //steps per uV.\n",
              "    }\n",
              "\n",
              "\tgetLatestData(channel=\"A0\",count=1) { //Return slice of specified size of the latest data from the specified channel\n",
              "\t\tlet ct = count;\n",
              "\t\tif(ct <= 1) {\n",
              "\t\t\treturn [this.data[channel][this.data.count-1]];\n",
              "\t\t}\n",
              "\t\telse {\n",
              "\t\t\tif(ct > this.data.count) {\n",
              "\t\t\t\tct = this.data.count;\n",
              "\t\t\t}\n",
              "\t\t\treturn this.data[channel].slice(this.data.count-ct,this.data.count);\n",
              "\t\t}\n",
              "\t}\n",
              "\n",
              "    bytesToInt16(x0,x1){\n",
              "\t\treturn x0 * 256 + x1;\n",
              "    }\n",
              "\n",
              "    int16ToBytes(y){ //Turns a 24 bit int into a 3 byte sequence\n",
              "        return [y & 0xFF , (y >> 8) & 0xFF];\n",
              "    }\n",
              "\n",
              "    bytesToInt24(x0,x1,x2){ //Turns a 3 byte sequence into a 24 bit int\n",
              "        return x0 * 65536 + x1 * 256 + x2;\n",
              "    }\n",
              "\n",
              "    int24ToBytes(y){ //Turns a 24 bit int into a 3 byte sequence\n",
              "        return [y & 0xFF , (y >> 8) & 0xFF , (y >> 16) & 0xFF];\n",
              "    }\n",
              "\n",
              "    decode(buffer = this.buffer) { //returns true if successful, returns false if not\n",
              "\n",
              "\t\tvar needle = this.searchString\n",
              "\t\tvar haystack = buffer;\n",
              "\t\tvar search = this.boyerMoore(needle);\n",
              "\t\tvar skip = search.byteLength;\n",
              "\t\tvar indices = [];\n",
              "\t\tlet newLines = 0;\n",
              "    \n",
              "\t\tfor (var i = search(haystack); i !== -1; i = search(haystack, i + skip)) {\n",
              "\t\t\tindices.push(i);\n",
              "\t\t}\n",
              "\t\t//console.log(indices);\n",
              "\t\tif(indices.length >= 2){\n",
              "\t\t\tfor(let k = 1; k < indices.length; k++) {\n",
              "\t\t\t\tif(indices[k] - indices[k-1] !== 105) {\n",
              "\t\t\t\t\t\n",
              "\t\t\t\t} //This is not a valid sequence going by size, drop sequence and return\n",
              "\t\t\t\telse {\n",
              "\t\t\t\t\tvar line = buffer.slice(indices[k-1],indices[k]+1); //Splice out this line to be decoded\n",
              "\t\t\t\t\t\n",
              "\t\t\t\t\t// line[0] = stop byte, line[1] = start byte, line[2] = counter, line[3:99] = ADC data 32x3 bytes, line[100-104] = Accelerometer data 3x2 bytes\n",
              "\n",
              "\t\t\t\t\t//line found, decode.\n",
              "\t\t\t\t\tif(this.data.count < this.maxBufferedSamples){\n",
              "\t\t\t\t\t\tthis.data.count++;\n",
              "\t\t\t\t\t}\n",
              "\n",
              "\t\t\t\t\tif(this.data.count-1 === 0) {this.data.ms[this.data.count-1]= Date.now(); this.data.startms = this.data.ms[0];}\n",
              "\t\t\t\t\telse {\n",
              "\t\t\t\t\t\tthis.data.ms[this.data.count-1]=this.data.ms[this.data.count-2]+this.updateMs;\n",
              "\t\t\t\t\t\t\n",
              "\t\t\t\t\t\tif(this.data.count >= this.maxBufferedSamples) {\n",
              "\t\t\t\t\t\t\tthis.data.ms.splice(0,5120);\n",
              "\t\t\t\t\t\t\tthis.data.ms.push(new Array(5120).fill(0));\n",
              "\t\t\t\t\t\t}\n",
              "\t\t\t\t\t}//Assume no dropped samples\n",
              "\t\t\t\t  var sample_count = line[2];\n",
              "\t\t\t\t  var sample_count_diff = sample_count-this.samples_count;\n",
              "          if(sample_count_diff<0){\n",
              "            sample_count_diff+=256;\n",
              "          }\n",
              "          if(sample_count_diff!=1)\n",
              "          {\n",
              "            console.error(\"dropped samples:\"+sample_count_diff.toString());\n",
              "          }\n",
              "          this.samples_count=sample_count;\n",
              "\n",
              "\t\t\t\t\tfor(var i = 3; i < 99; i+=3) {\n",
              "\t\t\t\t\t\tvar channel = \"A\"+(i-3)/3;\n",
              "\t\t\t\t\t\tthis.data[channel][this.data.count-1]=this.bytesToInt24(line[i],line[i+1],line[i+2]);\n",
              "\t\t\t\t\t\tif(this.data.count >= this.maxBufferedSamples) { \n",
              "\t\t\t\t\t\t\tthis.data[channel].splice(0,5120);\n",
              "\t\t\t\t\t\t\tthis.data[channel].push(new Array(5120).fill(0));//shave off the last 10 seconds of data if buffer full (don't use shift())\n",
              "\t\t\t\t\t\t}\n",
              "\t\t\t\t\t\t\t//console.log(this.data[channel][this.data.count-1],indices[k], channel)\n",
              "\t\t\t\t\t}\n",
              "\n",
              "\t\t\t\t\tthis.data[\"Ax\"][this.data.count-1]=this.bytesToInt16(line[99],line[100]);\n",
              "\t\t\t\t\tthis.data[\"Ay\"][this.data.count-1]=this.bytesToInt16(line[101],line[102]);\n",
              "\t\t\t\t\tthis.data[\"Az\"][this.data.count-1]=this.bytesToInt16(line[103],line[104]);\n",
              "\n",
              "\t\t\t\t\t\n",
              "\t\t\t\t\tif(this.data.count >= this.maxBufferedSamples) { \n",
              "\t\t\t\t\t\tthis.data[\"Ax\"].splice(0,5120);\n",
              "\t\t\t\t\t\tthis.data[\"Ay\"].splice(0,5120);\n",
              "\t\t\t\t\t\tthis.data[\"Az\"].splice(0,5120);\n",
              "\t\t\t\t\t\tthis.data[\"Ax\"].push(new Array(5120).fill(0))\n",
              "\t\t\t\t\t\tthis.data[\"Ay\"].push(new Array(5120).fill(0))\n",
              "\t\t\t\t\t\tthis.data[\"Az\"].push(new Array(5120).fill(0))\n",
              "\t\t\t\t\t\tthis.data.count -= 5120;\n",
              "\t\t\t\t\t}\n",
              "\t\t\t\t\t//console.log(this.data)\n",
              "\t\t\t\t\tnewLines++;\n",
              "\t\t\t\t\t//console.log(indices[k-1],indices[k])\n",
              "\t\t\t\t\t//console.log(buffer[indices[k-1],buffer[indices[k]]])\n",
              "\t\t\t\t\t//indices.shift();\n",
              "\t\t\t\t}\n",
              "\t\t\t\t\n",
              "\t\t\t}\n",
              "\t\t\tif(newLines > 0) buffer.splice(0,indices[indices.length-1]);\n",
              "   \n",
              "\t\t\treturn newLines;\n",
              "\t\t\t//Continue\n",
              "\t\t}\n",
              "\t\t//else {this.buffer = []; return false;}\n",
              "\t}\n",
              "\t//Callbacks\n",
              "\tonDecodedCallback(newLinesInt){\n",
              "\t\t//console.log(\"new samples:\", newLinesInt);\n",
              "    this.bufferednewLines=this.bufferednewLines+newLinesInt;\n",
              "    //if(this.bufferednewLines>this.data_slice_size)\n",
              "    //  {\n",
              "    //    this.bufferednewLines=this.data_slice_size;\n",
              "    //  }\n",
              "    if(this.bufferednewLines>512/this.fps)\n",
              "    {\n",
              "      this.bufferednewLines=512/this.fps;\n",
              "\n",
              "        this.takeandsendSlice(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
              "    }\n",
              "\t\t//console.log(\"this.bufferednewLines:\", this.bufferednewLines);\n",
              "    //this.takeSlice(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
              "    //this.takeandsendSlice(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
              "    //this.takeandsendSliceBroadcast(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
              " \t}\n",
              "\n",
              "\tonConnectedCallback() {\n",
              "\t\tconsole.log(\"port connected!\");\n",
              "\t}\n",
              "\n",
              "\tonDisconnectedCallback() {\n",
              "\t\tconsole.log(\"port disconnected!\");\n",
              "\t}\n",
              "\n",
              "\tonReceive(value){\n",
              "\t\tthis.buffer.push(...value);\n",
              "\n",
              "\t\tlet newLines = this.decode(this.buffer);\n",
              "\t\t//console.log(this.data)\n",
              "\t\t//console.log(\"decoding... \", this.buffer.length)\n",
              "\t\tif(newLines !== false && newLines !== 0 && !isNaN(newLines) ) this.onDecodedCallback(newLines);\n",
              "\t}\n",
              "\n",
              "\tasync onPortSelected(port,baud=this.baudrate) {\n",
              "\t\ttry{\n",
              "\t\t\ttry {\n",
              "\t\t\t\tawait port.open({ baudRate: baud, bufferSize: this.readBufferSize });\n",
              "\t\t\t\tthis.onConnectedCallback();\n",
              "\t\t\t\tthis.connected = true;\n",
              "\t\t\t\tthis.subscribed = true;\n",
              "\t\t\t\tthis.subscribe(port);//this.subscribeSafe(port);\n",
              "\t\t\n",
              "\t\t\t} //API inconsistency in syntax between linux and windows\n",
              "\t\t\tcatch {\n",
              "\t\t\t\tawait port.open({ baudrate: baud, buffersize: this.readBufferSize });\n",
              "\t\t\t\tthis.onConnectedCallback();\n",
              "\t\t\t\tthis.connected = true;\n",
              "\t\t\t\tthis.subscribed = true;\n",
              "\t\t\t\tthis.subscribe(port);//this.subscribeSafe(port);\n",
              "\t\t\t}\n",
              "\t\t}\n",
              "\t\tcatch(err){\n",
              "\t\t\tconsole.log(err);\n",
              "\t\t\tthis.connected = false;\n",
              "\t\t}\n",
              "\t}\n",
              "\n",
              "\tasync subscribe(port){\n",
              "\t\tif (this.port.readable && this.subscribed === true) {\n",
              "\t\t\tthis.reader = port.readable.getReader();\n",
              "\t\t\tconst streamData = async () => {\n",
              "\t\t\t\ttry {\n",
              "\t\t\t\t\tconst { value, done } = await this.reader.read();\n",
              "\t\t\t\t\tif (done || this.subscribed === false) {\n",
              "\t\t\t\t\t\t// Allow the serial port to be closed later.\n",
              "\t\t\t\t\t\tawait this.reader.releaseLock();\n",
              "\t\t\t\t\t\t\n",
              "\t\t\t\t\t}\n",
              "\t\t\t\t\tif (value) {\n",
              "\t\t\t\t\t\t//console.log(value.length);\n",
              "\t\t\t\t\t\ttry{\n",
              "\t\t\t\t\t\t\tthis.onReceive(value);\n",
              "\t\t\t\t\t\t}\n",
              "\t\t\t\t\t\tcatch (err) {console.log(err)}\n",
              "\t\t\t\t\t\t//console.log(\"new Read\");\n",
              "\t\t\t\t\t\t//console.log(this.decoder.decode(value));\n",
              "\t\t\t\t\t}\n",
              "\t\t\t\t\tif(this.subscribed === true) {\n",
              "\t\t\t\t\t\tsetTimeout(()=>{streamData();}, this.readRate);//Throttled read 1/512sps = 1.953ms/sample @ 103 bytes / line or 1030bytes every 20ms\n",
              "\t\t\t\t\t}\n",
              "\t\t\t\t} catch (error) {\n",
              "\t\t\t\t\tconsole.log(error);// TODO: Handle non-fatal read error.\n",
              "                    if(error.message.includes('framing') || error.message.includes('overflow') || error.message.includes('Overflow') || error.message.includes('break')) {\n",
              "                        this.subscribed = false;\n",
              "                        setTimeout(async ()=>{\n",
              "\t\t\t\t\t\t\ttry{\n",
              "                            if (this.reader) {\n",
              "                                await this.reader.releaseLock();\n",
              "                                this.reader = null;\n",
              "                            }\n",
              "\t\t\t\t\t\t\t} catch (er){ console.error(er);}\n",
              "                            this.subscribed = true; \n",
              "                            this.subscribe(port);\n",
              "                            //if that fails then close port and reopen it\n",
              "                        },30); //try to resubscribe \n",
              "                    } else if (error.message.includes('parity') || error.message.includes('Parity') || error.message.includes('overrun') ) {\n",
              "                        if(this.port){\n",
              "                            this.subscribed = false;\n",
              "                            setTimeout(async () => {\n",
              "\t\t\t\t\t\t\t\ttry{\n",
              "                                if (this.reader) {\n",
              "                                    await this.reader.releaseLock();\n",
              "                                    this.reader = null;\n",
              "                                }\n",
              "                                await port.close();\n",
              "\t\t\t\t\t\t\t\t} catch (er){ console.error(er);}\n",
              "                                //this.port = null;\n",
              "                                this.connected = false;\n",
              "                                setTimeout(()=>{this.onPortSelected(this.port)},100); //close the port and reopen\n",
              "                            }, 50);\n",
              "                        }\n",
              "                    }\n",
              "                     else {\n",
              "                        this.closePort();\t\n",
              "                    }\t\n",
              "\t\t\t\t}\n",
              "\t\t\t}\n",
              "\t\t\tstreamData();\n",
              "\t\t}\n",
              "\t}\n",
              "\n",
              "\t//Unfinished\n",
              "\tasync subscribeSafe(port) { //Using promises instead of async/await to cure hangs when the serial update does not meet tick requirements\n",
              "\t\tvar readable = new Promise((resolve,reject) => {\n",
              "\t\t\twhile(this.port.readable && this.subscribed === true){\n",
              "\t\t\t\tthis.reader = port.readable.getReader();\n",
              "\t\t\t\tvar looper = true;\n",
              "\t\t\t\tvar prom1 = new Promise((resolve,reject) => {\n",
              "\t\t\t\t\treturn this.reader.read();\n",
              "\t\t\t\t});\n",
              "\n",
              "\t\t\t\tvar prom2 = new Promise((resolve,reject) => {\n",
              "\t\t\t\t\tsetTimeout(resolve,100,\"readfail\");\n",
              "\t\t\t\t});\n",
              "\t\t\t\twhile(looper === true ) {\n",
              "\t\t\t\t\t//console.log(\"reading...\");\n",
              "\t\t\t\t\tPromise.race([prom1,prom2]).then((result) => {\n",
              "\t\t\t\t\t\tconsole.log(\"newpromise\")\n",
              "\t\t\t\t\t\tif(result === \"readfail\"){\n",
              "\t\t\t\t\t\t\tconsole.log(result);\n",
              "\t\t\t\t\t\t}\n",
              "\t\t\t\t\t\telse{\n",
              "\t\t\t\t\t\t\tconst {value, done} = result;\n",
              "\t\t\t\t\t\t\tif(done === true || this.subscribed === true) { var donezo = new Promise((resolve,reject) => {\n",
              "\t\t\t\t\t\t\t\tresolve(this.reader.releaseLock())}).then(() => {\n",
              "\t\t\t\t\t\t\t\t\tlooper = false;\n",
              "\t\t\t\t\t\t\t\t\treturn;\n",
              "\t\t\t\t\t\t\t\t});\n",
              "\t\t\t\t\t\t\t}\n",
              "\t\t\t\t\t\t\telse{\n",
              "\t\t\t\t\t\t\t\tthis.onReceive(value);\n",
              "\t\t\t\t\t\t\t}\n",
              "\t\t\t\t\t\t}\n",
              "\t\t\t\t\t});\n",
              "\t\t\t\t}\n",
              "\t\t\t}\n",
              "\t\t\tresolve(\"not readable\");\n",
              "\t\t});\n",
              "\t}\n",
              "\n",
              "\tasync closePort(port=this.port) {\n",
              "\t\t//if(this.reader) {this.reader.releaseLock();}\n",
              "\t\tif(this.port){\n",
              "\t\t\tthis.subscribed = false;\n",
              "\t\t\tsetTimeout(async () => {\n",
              "\t\t\t\tif (this.reader) {\n",
              "\t\t\t\t\tawait this.reader.releaseLock();\n",
              "\t\t\t\t\tthis.reader = null;\n",
              "\t\t\t\t}\n",
              "\t\t\t\tawait port.close();\n",
              "\t\t\t\tthis.port = null;\n",
              "\t\t\t\tthis.connected = false;\n",
              "\t\t\t\tthis.onDisconnectedCallback();\n",
              "\t\t\t}, 100);\n",
              "\t\t}\n",
              "\t}\n",
              "\n",
              "\tasync setupSerialAsync(baudrate=this.baudrate) { //You can specify baudrate just in case\n",
              "\n",
              "\t\tconst filters = [\n",
              "\t\t\t{ usbVendorId: 0x10c4, usbProductId: 0x0043 } //CP2102 filter (e.g. for UART via ESP32)\n",
              "\t\t];\n",
              "\n",
              "\t\tthis.port = await navigator.serial.requestPort();\n",
              "\t\tnavigator.serial.addEventListener(\"disconnect\",(e) => {\n",
              "\t\t\tthis.closePort(this.port);\n",
              "\t\t});\n",
              "\t\tthis.onPortSelected(this.port,baudrate);\n",
              "\n",
              "\t\t//navigator.serial.addEventListener(\"onReceive\", (e) => {console.log(e)});//this.onReceive(e));\n",
              "\n",
              "\t}\n",
              "\n",
              "\n",
              "\t//Boyer Moore fast byte search method copied from https://codereview.stackexchange.com/questions/20136/uint8array-indexof-method-that-allows-to-search-for-byte-sequences\n",
              "\tasUint8Array(input) {\n",
              "\t\tif (input instanceof Uint8Array) {\n",
              "\t\t\treturn input;\n",
              "\t\t} else if (typeof(input) === 'string') {\n",
              "\t\t\t// This naive transform only supports ASCII patterns. UTF-8 support\n",
              "\t\t\t// not necessary for the intended use case here.\n",
              "\t\t\tvar arr = new Uint8Array(input.length);\n",
              "\t\t\tfor (var i = 0; i < input.length; i++) {\n",
              "\t\t\tvar c = input.charCodeAt(i);\n",
              "\t\t\tif (c > 127) {\n",
              "\t\t\t\tthrow new TypeError(\"Only ASCII patterns are supported\");\n",
              "\t\t\t}\n",
              "\t\t\tarr[i] = c;\n",
              "\t\t\t}\n",
              "\t\t\treturn arr;\n",
              "\t\t} else {\n",
              "\t\t\t// Assume that it's already something that can be coerced.\n",
              "\t\t\treturn new Uint8Array(input);\n",
              "\t\t}\n",
              "\t}\n",
              "\n",
              "\tboyerMoore(patternBuffer) {\n",
              "\t\t// Implementation of Boyer-Moore substring search ported from page 772 of\n",
              "\t\t// Algorithms Fourth Edition (Sedgewick, Wayne)\n",
              "\t\t// http://algs4.cs.princeton.edu/53substring/BoyerMoore.java.html\n",
              "\t\t\n",
              "//\t\tUSAGE:\n",
              "\t\t\t// needle should be ASCII string, ArrayBuffer, or Uint8Array\n",
              "\t\t\t// haystack should be an ArrayBuffer or Uint8Array\n",
              "//\t\t\tvar search = boyerMoore(needle);\n",
              "//\t\t\tvar skip = search.byteLength;\n",
              "//\t\t\tvar indices = [];\n",
              "//\t\t\tfor (var i = search(haystack); i !== -1; i = search(haystack, i + skip)) {\n",
              "//\t\t\t\tindices.push(i);\n",
              "//\t\t\t}\n",
              "\t\t\n",
              "\t\tvar pattern = this.asUint8Array(patternBuffer);\n",
              "\t\tvar M = pattern.length;\n",
              "\t\tif (M === 0) {\n",
              "\t\t\tthrow new TypeError(\"patternBuffer must be at least 1 byte long\");\n",
              "\t\t}\n",
              "\t\t// radix\n",
              "\t\tvar R = 256;\n",
              "\t\tvar rightmost_positions = new Int32Array(R);\n",
              "\t\t// position of the rightmost occurrence of the byte c in the pattern\n",
              "\t\tfor (var c = 0; c < R; c++) {\n",
              "\t\t\t// -1 for bytes not in pattern\n",
              "\t\t\trightmost_positions[c] = -1;\n",
              "\t\t}\n",
              "\t\tfor (var j = 0; j < M; j++) {\n",
              "\t\t\t// rightmost position for bytes in pattern\n",
              "\t\t\trightmost_positions[pattern[j]] = j;\n",
              "\t\t}\n",
              "\t\tvar boyerMooreSearch = (txtBuffer, start, end) => {\n",
              "\t\t\t// Return offset of first match, -1 if no match.\n",
              "\t\t\tvar txt = this.asUint8Array(txtBuffer);\n",
              "\t\t\tif (start === undefined) start = 0;\n",
              "\t\t\tif (end === undefined) end = txt.length;\n",
              "\t\t\tvar pat = pattern;\n",
              "\t\t\tvar right = rightmost_positions;\n",
              "\t\t\tvar lastIndex = end - pat.length;\n",
              "\t\t\tvar lastPatIndex = pat.length - 1;\n",
              "\t\t\tvar skip;\n",
              "\t\t\tfor (var i = start; i <= lastIndex; i += skip) {\n",
              "\t\t\t\tskip = 0;\n",
              "\t\t\t\tfor (var j = lastPatIndex; j >= 0; j--) {\n",
              "\t\t\t\tvar c = txt[i + j];\n",
              "\t\t\t\tif (pat[j] !== c) {\n",
              "\t\t\t\t\tskip = Math.max(1, j - right[c]);\n",
              "\t\t\t\t\tbreak;\n",
              "\t\t\t\t}\n",
              "\t\t\t\t}\n",
              "\t\t\t\tif (skip === 0) {\n",
              "\t\t\t\treturn i;\n",
              "\t\t\t\t}\n",
              "\t\t\t}\n",
              "\t\t\treturn -1;\n",
              "\t\t};\n",
              "\t\tboyerMooreSearch.byteLength = pattern.byteLength;\n",
              "\t\treturn boyerMooreSearch;\n",
              "\t}\n",
              "\t//---------------------end copy/pasted solution------------------------\n",
              "\n",
              "    async  takeandsendSlice(data_slice_from,data_slice_to) {\n",
              "        //this.lastnewLines=this.bufferednewLines;\n",
              "     //if(this.ready_to_send_data&&this.bufferednewLines){//&&this.data_slice[0].length)\n",
              "     if(this.ready_to_send_data&&this.bufferednewLines)//&&this.data_slice[0].length)\n",
              "     {\n",
              "      //this.ready_to_send_data = false;\n",
              "      this.data_slice = [\n",
              "        //device.data.ms.slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+0].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+1].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+2].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+3].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+4].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+5].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+6].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+7].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+8].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+9].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+10].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+11].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+12].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+13].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+14].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+15].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+16].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+17].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+18].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+19].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+20].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+21].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+22].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+23].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+24].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+25].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+26].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+27].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+28].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+29].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+30].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+31].slice(data_slice_from,data_slice_to)\n",
              "        ];\n",
              "  this.bufferednewLines=0;\n",
              "  //const buffer = new Uint8Array(10);\n",
              "  //for (let i = 0; i < buffer.byteLength; ++i) {\n",
              "  //  buffer[i] = i\n",
              "  //}\n",
              "  var array_to_send_as_json = JSON.stringify(this.data_slice);\n",
              "  //document.body.appendChild(document.createTextNode('sending ready'));\n",
              "  this.data_send_count++;\n",
              "  //if(this.channel==None)\n",
              "  //{\n",
              "  //  this.channel = await google.colab.kernel.comms.open('comm_target1', array_to_send_as_json, []);\n",
              "    //this.channel = await google.colab.kernel.comms.open(this.data_send_count.toString(), array_to_send_as_json, []);\n",
              "  //} else \n",
              "  //{\n",
              "    //this.channel.send(this.data_send_count.toString())\n",
              "  //}\n",
              "  //document.body.appendChild(document.createTextNode(array_to_send_as_json));\n",
              "  const channel = await google.colab.kernel.comms.open('comm_target1', array_to_send_as_json, []);\n",
              "  //const channel = await google.colab.kernel.comms.open('comm_target1', 'the data', [buffer.buffer]);\n",
              "  let success = false;\n",
              "  for await (const message of channel.messages) {\n",
              "    if (message.data.response == 'got comm open!') {\n",
              "      const responseBuffer = new Uint8Array(message.buffers[0]);\n",
              "      for (let i = 0; i < buffer.length; ++i) {\n",
              "        if (responseBuffer[i] != buffer[i]) {\n",
              "          console.error('comm buffer different at ' + i);\n",
              "          document.body.appendChild(document.createTextNode('comm buffer different at2 ' + i));\n",
              "          return;\n",
              "        }\n",
              "      }\n",
              "      // Close the channel once the expected message is received. This should\n",
              "      // cause the messages iterator to complete and for the for-await loop to\n",
              "      // end.\n",
              "      //console.error('comm buffer same ' + responseBuffer);\n",
              "      //document.body.appendChild(document.createTextNode('comm buffer same2 ' + responseBuffer));\n",
              "      channel.close();\n",
              "    }\n",
              "    if (this.generate_wavegan)\n",
              "    {\n",
              "      await playAudio1(message.data.response);\n",
              "    }\n",
              "    if (this.generate_stylegan2)\n",
              "    {\n",
              "      await displayPhoto1(message.data.response);\n",
              "    }\n",
              "  }\n",
              "      //this.ready_to_send_data = true;\n",
              "  document.body.appendChild(document.createTextNode('done2.'));\n",
              "     } \n",
              "\n",
              "    }\n",
              "\n",
              "}\n",
              "\n",
              "device = new eeg32();\n",
              "\n",
              "    connect = async () => {\n",
              "        await this.device.setupSerialAsync();\n",
              "    }\n",
              "\n",
              "    disconnect = () => {\n",
              "        if (this.ui) this.ui.deleteNode()\n",
              "        this.device.closePort();\n",
              "    }\n",
              "\n",
              "\n",
              "        const canvas = document.createElement('canvas');\n",
              "      const audio = document.createElement('audio');\n",
              "      const audio1 = document.createElement('audio');\n",
              "      const audio2 = document.createElement('audio');\n",
              "\n",
              "          var ctx = canvas.getContext(\"2d\");\n",
              "\n",
              "      var image = new Image();\n",
              "      image.onload = function() {\n",
              "        ctx.drawImage(image, 0, 0);\n",
              "      };\n",
              "const div = document.createElement('div');\n",
              "const btnconnect = document.createElement('button');\n",
              "const btndisconnect = document.createElement('button');\n",
              "const capture = document.createElement('button');\n",
              "                  \n",
              "    async function takePhoto2(quality=1) {\n",
              "      btnconnect.remove();\n",
              "      capture.remove();\n",
              "      device.ready_to_send_data = true;\n",
              "    }\n",
              "\n",
              "    async function takePhoto(quality=1) {\n",
              "\n",
              "      btnconnect.textContent = 'connect';\n",
              "      div.appendChild(btnconnect);\n",
              "      btnconnect.onclick = this.connect;\n",
              "      \n",
              "      btndisconnect.textContent = 'disconnect';\n",
              "      div.appendChild(btndisconnect);\n",
              "      btndisconnect.onclick = this.disconnect;\n",
              "      \n",
              "      capture.textContent = 'Capture';\n",
              "      capture.onclick = takePhoto2;\n",
              "      div.appendChild(capture);\n",
              "     \n",
              "      div.appendChild(canvas);\n",
              "      div.appendChild(audio);\n",
              "      div.appendChild(audio1);\n",
              "      div.appendChild(audio2);\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "         await new Promise((resolve) => capture.onclick = resolve);\n",
              " \n",
              "      btnconnect.remove();\n",
              "      capture.remove();\n",
              "      device.ready_to_send_data = true;\n",
              "    }\n",
              "\n",
              "    async function takePhoto1(quality=1) {  \n",
              "      //var data_slice_send=this.device.data_slice;\n",
              "      //var data_slice_send=[this.device.data_slice[0],this.device.data_slice[1]];\n",
              "      //var data_slice_send=[this.device.data_slice[0]];\n",
              "      var data_slice_send=[[this.device.data_slice[0][0]]];\n",
              "\t  \t//console.log(\"data_slice_send[0].length:\", data_slice_send[0].length);\n",
              "  \t\t//console.log(\"device.bufferednewLines:\", device.bufferednewLines);\n",
              "      device.bufferednewLines=0;\n",
              "      return data_slice_send;      \n",
              "    }\n",
              "\n",
              "    async function displayPhoto1(photodata,photoWidth=400,photoHeight=400) {\n",
              "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
              "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
              "      await displayPhoto2(photodata,photoWidth,photoHeight);\n",
              "    }\n",
              "    async function displayPhoto2(photodata,photoWidth,photoHeight) {\n",
              "      if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
              "      if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
              "     image.src = photodata;\n",
              "    }\n",
              "    var audio_now=0;\n",
              "    async function playAudio1(audiodata,photoWidth=200,photoHeight=200) {\n",
              "      //const canvas = document.createElement('canvas');\n",
              "      canvas.width = photoWidth;\n",
              "      canvas.height = photoHeight;\n",
              "      //audio.controls = true;\n",
              "      //audio.autoplay = true;\n",
              "      audio1.controls = true;\n",
              "      audio1.autoplay = true;\n",
              "      audio2.controls = true;\n",
              "      audio2.autoplay = true;\n",
              "\n",
              "      //canvas.getContext('2d').drawImage(photodata, 0, 0);\n",
              "      //var canvas = document.getElementById(\"c\");\n",
              "      ///var ctx = canvas.getContext(\"2d\");\n",
              "\n",
              "      ///var image = new Image();\n",
              "      ///image.onload = function() {\n",
              "      ///  ctx.drawImage(image, 0, 0);\n",
              "      ///};\n",
              "      //audio.src = audiodata;\n",
              "      //audio.play()\n",
              "      if(audio_now%2==0)\n",
              "      {\n",
              "        audio1.src = audiodata;\n",
              "        audio1.play()\n",
              "      }\n",
              "      else\n",
              "      {\n",
              "        audio2.src = audiodata;\n",
              "        audio2.play()\n",
              "      }\n",
              "      audio_now++;\n",
              "\n",
              "    }\n",
              "    \n",
              "  takePhoto();\n",
              "  data_count=0;\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "stream",
          "text": [
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "FLhd7pdGj-PY",
        "outputId": "5f53f923-aabb-4cb5-80ee-86116a6ede89"
      },
      "source": [
        "stop"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRKTkV4VtljO"
      },
      "source": [
        "                seed = 6600\n",
        "                # creating random latent vector\n",
        "                rnd = np.random.RandomState(seed)\n",
        "                __z = rnd.randn(1, 512).astype('float32')\n",
        "                # running mapping network\n",
        "                time1101=perf_counter()\n",
        "                #print (f'1101: {(time1101-time000):.1f}s')\n",
        "                dlatents = generator.mapping_network(__z)  \n",
        "                time1102=perf_counter()\n",
        "                #print (f'1102: {(time1102-time000):.1f}s')\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy-BZkWyRFyd"
      },
      "source": [
        "if True:\n",
        "                #__z = psd_array * vol\n",
        "                dlatents = generator.mapping_network(__z)\n",
        "                time1103=perf_counter()\n",
        "                #print (f'1103: {(time1103-time000):.1f}s')\n",
        "                image_out = generator.synthesis_network(dlatents)\n",
        "                time1104=perf_counter()\n",
        "                #print (f'1104: {(time1104-time000):.1f}s')\n",
        "                #converting image/s to uint8\n",
        "                img = convert_images_to_uint8(image_out, nchw_to_nhwc=True, uint8_cast=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI2EA8snty4R"
      },
      "source": [
        "        plt.axis('off')\n",
        "        plt.imshow(img.numpy()[0])\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTE7npmqgGNu"
      },
      "source": [
        "print(__z.astype('float32'))\n",
        "dlatents = generator.mapping_network(__z.astype('float32'))\n",
        "print(dlatents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6hKLPGufmbZ"
      },
      "source": [
        "dlatents = generator.mapping_network(__z[0])\n",
        "out = generator.synthesis_network(dlatents)\n",
        "#converting image/s to uint8\n",
        "images = convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc8_2gSsB-7l"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "images = Gs.run(_z1, None, **Gs_kwargs)\n",
        "for image in images:\n",
        "                  plt.axis('off')\n",
        "                  print(_z1)\n",
        "                  print(image)\n",
        "                  image_pil=PIL.Image.fromarray(image, 'RGB')\n",
        "                  plt.imshow(image_pil)\n",
        "                  print(image_pil)\n",
        "                  image_asarray=np.asarray(image_pil)\n",
        "                  print(image_asarray)\n",
        "                  time1111=perf_counter()\n",
        "                  #print (f'1111: {(time1111-time000):.1f}s')\n",
        "                  global video_out\n",
        "                  video_out.append_data(image_asarray)\n",
        "                  time1112=perf_counter()\n",
        "                  #print (f'1112: {(time1112-time000):.1f}s')\n",
        "                  img=image_pil.resize((xsize,ysize),PIL.Image.ANTIALIAS)\n",
        "                  print(img)\n",
        "                  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpfkxCYJKznp"
      },
      "source": [
        "print(latents)\n",
        "image_out = g_clone([latents, labels], training=False, truncation_psi=0.5)\n",
        "print(image_out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2swgZsKgIbV"
      },
      "source": [
        "#while True:\n",
        "#  target_func1('{1}','{1}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHm9yDes4i-V"
      },
      "source": [
        "stop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KubmOemcqU_4"
      },
      "source": [
        "out.close()\n",
        "from IPython import display as ipythondisplay\n",
        "import io\n",
        "import os\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "def show_video(vid):\n",
        "  ext = os.path.splitext(vid)[-1][1:]\n",
        "  video = io.open(vid, 'r+b').read()\n",
        "  ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "              loop controls style=\"height: 400px;\">\n",
        "              <source src=\"data:video/{1}';base64,{0}\" type=\"video/{1}\" />\n",
        "              </video>'''.format(base64.b64encode(video).decode('ascii'), ext)))\n",
        "\n",
        "show_video('/content/out/output.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRaKPKotYCq4"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/out/output.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6JXcX4OYAsw"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp -r -v \"/content/out\" \"/content/gdrive/MyDrive/EEG-GAN-audio-video\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6Xw4_hXaqno"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}